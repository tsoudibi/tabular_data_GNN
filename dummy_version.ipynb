{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import seed_everything\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import torch_geometric\n",
    "from tqdm import tqdm, trange\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cuda')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48842, 14]) torch.Size([48842])\n",
      "[9, 16, 7, 15, 6, 5, 2, 42]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.995129</td>\n",
       "      <td>0.351675</td>\n",
       "      <td>-1.197259</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.046942</td>\n",
       "      <td>-0.945524</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.776316</td>\n",
       "      <td>1.394723</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390683</td>\n",
       "      <td>-0.277844</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.886874</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.505691</td>\n",
       "      <td>-0.815954</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.841104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>-0.849254</td>\n",
       "      <td>0.640492</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.195490</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.098933</td>\n",
       "      <td>-0.334178</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.411808</td>\n",
       "      <td>-0.357510</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>-1.213941</td>\n",
       "      <td>0.111984</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-1.648120</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.974183</td>\n",
       "      <td>0.930494</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>1.871315</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0     -0.995129  0.351675        -1.197259     -0.144804     -0.217127   \n",
       "1     -0.046942 -0.945524        -0.419335     -0.144804     -0.217127   \n",
       "2     -0.776316  1.394723         0.747550     -0.144804     -0.217127   \n",
       "3      0.390683 -0.277844        -0.030373      0.886874     -0.217127   \n",
       "4     -1.505691 -0.815954        -0.030373     -0.144804     -0.217127   \n",
       "...         ...       ...              ...           ...           ...   \n",
       "48837 -0.849254  0.640492         0.747550     -0.144804     -0.217127   \n",
       "48838  0.098933 -0.334178        -0.419335     -0.144804     -0.217127   \n",
       "48839  1.411808 -0.357510        -0.419335     -0.144804     -0.217127   \n",
       "48840 -1.213941  0.111984        -0.419335     -0.144804     -0.217127   \n",
       "48841  0.974183  0.930494        -0.419335      1.871315     -0.217127   \n",
       "\n",
       "       hours-per-week  workclass  education  marital-status  occupation  \\\n",
       "0           -0.034087        4.0        1.0             4.0         7.0   \n",
       "1            0.772930        4.0       11.0             2.0         5.0   \n",
       "2           -0.034087        2.0        7.0             2.0        11.0   \n",
       "3           -0.034087        4.0       15.0             2.0         7.0   \n",
       "4           -0.841104        0.0       15.0             4.0         0.0   \n",
       "...               ...        ...        ...             ...         ...   \n",
       "48837       -0.195490        4.0        7.0             2.0        13.0   \n",
       "48838       -0.034087        4.0       11.0             2.0         7.0   \n",
       "48839       -0.034087        4.0       11.0             6.0         1.0   \n",
       "48840       -1.648120        4.0       11.0             4.0         1.0   \n",
       "48841       -0.034087        5.0       11.0             2.0         4.0   \n",
       "\n",
       "       relationship  race  gender  native-country  income  \n",
       "0               3.0   2.0     1.0            39.0       0  \n",
       "1               0.0   4.0     1.0            39.0       0  \n",
       "2               0.0   4.0     1.0            39.0       1  \n",
       "3               0.0   2.0     1.0            39.0       1  \n",
       "4               3.0   4.0     0.0            39.0       0  \n",
       "...             ...   ...     ...             ...     ...  \n",
       "48837           5.0   4.0     0.0            39.0       0  \n",
       "48838           0.0   4.0     1.0            39.0       1  \n",
       "48839           4.0   4.0     0.0            39.0       0  \n",
       "48840           3.0   4.0     1.0            39.0       0  \n",
       "48841           5.0   4.0     0.0            39.0       1  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature from csv\n",
    "RAW_data = pd.read_csv('data/adult.csv')\n",
    "CAT = ['workclass','education','marital-status','occupation','relationship','race','gender','native-country']\n",
    "NUM = ['age','fnlwgt','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "LABEL = 'income'\n",
    "# RAW_data = pd.read_csv('data/compass_old.csv')\n",
    "# CAT=['sex','age_cat','race','c_charge_degree','decile_score.1','score_text','v_type_of_assessment','v_decile_score','v_score_text']\n",
    "# NUM=['age','juv_fel_count','juv_misd_count','juv_other_count','priors_count','days_b_screening_arrest','c_days_from_compas','end']\n",
    "# LABEL = 'is_recid'\n",
    "# convert categorical data to ordinal data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "data_pd = RAW_data.copy()\n",
    "data_pd[CAT] = enc.fit_transform(RAW_data[CAT])\n",
    "# data_pd = pd.get_dummies(RAW_data, columns=CAT, dtype=float)\n",
    "# label to category\n",
    "data_pd[LABEL] = data_pd[LABEL].astype('category').cat.codes\n",
    "\n",
    "# realign data to num + cat\n",
    "data_pd = data_pd[NUM + CAT + [LABEL]]\n",
    "\n",
    "# caculate unique value of each categorical feature\n",
    "cat_num = [len(data_pd[col].unique()) for col in CAT]\n",
    "\n",
    "# normalize numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_pd[NUM] = scaler.fit_transform(data_pd[NUM])\n",
    "\n",
    "# convert data to tensor\n",
    "x = torch.tensor(data_pd.drop(columns=[LABEL]).values, dtype=torch.float, device=DEVICE)  # [48842, 108]\n",
    "y = torch.tensor(data_pd[LABEL].values, dtype=torch.long, device=DEVICE) # [48842]\n",
    "print(x.shape, y.shape)\n",
    "print(cat_num)\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_improtance_extractor():\n",
    "    def __init__(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        pass\n",
    "    def update(self, new_feature_importance):\n",
    "        if self.iter == 0:\n",
    "            self.feature_importance = new_feature_importance\n",
    "        else:\n",
    "            self.feature_importance += new_feature_importance\n",
    "        self.iter += 1\n",
    "        return\n",
    "    \n",
    "    def get(self):\n",
    "        return (self.feature_importance / self.iter)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        return\n",
    "extractor = feature_improtance_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_graph(torch.nn.Module):\n",
    "    def __init__(self, NUM, CAT, LABEL, cat_num):\n",
    "        super(K_graph, self).__init__()\n",
    "        '''\n",
    "        num_cols: number of numerical columns\n",
    "        cat_cols: number of categorical columns\n",
    "        label_cols: number of label columns\n",
    "        cat_num: number of unique value of each categorical columns\n",
    "        '''\n",
    "        self.hidden_dim = 128\n",
    "        # order: num -> cat -> label\n",
    "        self.num_cols = len(NUM)\n",
    "        self.cat_cols = len(CAT)\n",
    "        self.label_cols = len(LABEL)\n",
    "        self.number_of_columns = self.num_cols + self.cat_cols \n",
    "        self.K = round(self.number_of_columns*0.5)\n",
    "        \n",
    "        # numerical feature\n",
    "        self.num_embeddings = torch.nn.ModuleList([torch.nn.Linear(1, self.hidden_dim) for i in range(self.num_cols)])\n",
    "        # categorical feature\n",
    "        self.cat_embeddings = torch.nn.ModuleList([torch.nn.Embedding(cat_num[i], self.hidden_dim) for i in range(self.cat_cols)])\n",
    "        \n",
    "        self.prediction = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim *( self.K + self.number_of_columns), self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Linear(self.hidden_dim, self.label_cols + 1)\n",
    "        )\n",
    "        \n",
    "        # feature importance learning\n",
    "        self.feature_importance_learners = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        ) \n",
    "        \n",
    "        # graph convolution layers\n",
    "        self.conv_GCN_input = torch_geometric.nn.GCNConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_GCN_input = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_1_input = torch_geometric.nn.GATConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        self.conv_GCN_2 = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        # self.transform = torch.nn.Linear(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, input_data, epoch = -1):\n",
    "        \n",
    "        # make feature embedding\n",
    "        num_data = input_data[:,:self.num_cols].unsqueeze(-1).unsqueeze(-1) \n",
    "        feature_embedding_num = torch.cat([self.num_embeddings[i](num_data[:,i]) for i in range(self.num_cols)], dim=1).reshape(len(input_data), -1) # [batch_size, num_cols * hidden_dim]\n",
    "        feature_embedding_num = torch.nn.ReLU()(feature_embedding_num)\n",
    "        feature_embedding_num = torch.layer_norm(feature_embedding_num, feature_embedding_num.shape)\n",
    "        # categorical feature\n",
    "        feature_embedding_cat = torch.cat([self.cat_embeddings[i](input_data[:,self.num_cols+i].long()) for i in range(self.cat_cols)], dim=1) # [batch_size, cat_cols * hidden_dim]\n",
    "        feature_embedding_cat = torch.layer_norm(feature_embedding_cat, feature_embedding_cat.shape)\n",
    "        # concat\n",
    "        feature_embedding = torch.cat((feature_embedding_num, feature_embedding_cat), dim=1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        # feature_embedding = feature_embedding.reshape((len(input_data), self.number_of_columns, -1)) # [batch_size, (num_cols + cat_cols), hidden_dim]\n",
    "        \n",
    "        # feature importance learning\n",
    "        feature_importance = torch.cat([self.feature_importance_learners(feature_embedding[:,i*self.hidden_dim:(i+1)*self.hidden_dim]) for i in range(self.number_of_columns)], dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance)\n",
    "        feature_importance = torch.layer_norm(feature_importance, feature_importance.shape)\n",
    "        # feature_importance = torch.softmax(feature_importance, dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance.shape)\n",
    "        # print(feature_importance.sum(dim=1))\n",
    "        # print(feature_importance)\n",
    "        \n",
    "        # weighted feature embedding \n",
    "        feature_embedding = feature_embedding.reshape((len(input_data),self.number_of_columns, -1)) * feature_importance.unsqueeze(-1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        feature_embedding = feature_embedding.reshape((len(input_data), -1)) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        \n",
    "        # top K feature importance\n",
    "        K = self.K\n",
    "        value, indices = torch.topk(feature_importance, K) # (value: [batch_size, k], indices: [batch_size, k])\n",
    "        mask = torch.zeros_like(feature_importance, device=DEVICE)\n",
    "        mask.scatter_(1, indices, 1)\n",
    "        # importance_topK = torch.where(mask > 0, feature_importance, torch.zeros(feature_importance.shape,device=DEVICE)) # [batch_size, cols]\n",
    "        importance_topK = torch.where(mask > 0, feature_importance, torch.empty(feature_importance.shape,device=DEVICE).fill_(-1e9)) # [batch_size, cols]\n",
    "        importance_topK = torch.softmax(importance_topK, dim=1) # [batch_size, cols]\n",
    "        # importance_topK = torch.stack([importance_topK.clone() for _ in range(self.number_of_columns)], dim=0) # [cols, batch_size, cols]\n",
    "        \n",
    "        extractor.update(feature_importance.sum(dim=0)/len(input_data))\n",
    "        del feature_embedding_num, feature_embedding_cat, num_data\n",
    "        del mask, feature_importance, value, indices\n",
    "        \n",
    "        \n",
    "        processed_data = []\n",
    "        processed_indices = []\n",
    "        for target_col in range(self.number_of_columns):\n",
    "            importance_topK_current = importance_topK.clone()# [batch_size, cols] \n",
    "            indices = importance_topK_current.T[target_col].nonzero().T[0] # selected samples' indices  \n",
    "            \n",
    "            if indices.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            importance_topK_current = importance_topK_current[importance_topK_current.T[target_col]>0]# [????, cols]\n",
    "            \n",
    "            # for target column, set its importance to 0. so that it will not be fully connected graph\n",
    "            # copy target column\n",
    "            tmp = torch.clone(importance_topK_current[:,target_col]) # [????], save for future weighted sum\n",
    "            importance_topK_current[:,target_col] = 0 # [????, cols]\n",
    "            # multiply to get weighted adj\n",
    "            weighted_adj = torch.matmul(importance_topK_current, importance_topK_current.T) # [batch_size, cols] * [cols, batch_size] = [batch_size, batch_size]\n",
    "            # prune the diagonal\n",
    "            weighted_adj = weighted_adj - torch.diag(weighted_adj.diagonal())\n",
    "\n",
    "            # construct graph\n",
    "            edge_index = weighted_adj.nonzero().T  # [2, num_edges]\n",
    "            edge_wight = weighted_adj[edge_index[0], edge_index[1]] # [num_edges]\n",
    "            edge_wight = torch.softmax(edge_wight, dim=0)\n",
    "\n",
    "            \n",
    "            if False:\n",
    "                print('in graph', target_col, 'nodes:', len(indices), 'edges:', len(edge_wight),'ratio', len(edge_wight)/(len(indices)**2+0.000001))\n",
    "            \n",
    "            # print(edge_wight)\n",
    "            # importance_topK_current[:,target_col] = tmp # [????, cols]\n",
    "            \n",
    "            features = (feature_embedding[indices]) # [????, cols*hidden_dim]\n",
    "            # features = (feature_embedding.reshape(len(input_data),self.number_of_columns,-1)[indices][:,target_col,:]) # [????, hidden_dim]\n",
    "            # print(features.shape)\n",
    "\n",
    "            # construct graph \n",
    "            data = Data(x=features, edge_index=edge_index, edge_weight=edge_wight, indices=indices) \n",
    "            \n",
    "            del features, edge_index, edge_wight, weighted_adj, importance_topK_current, tmp\n",
    "            \n",
    "            # apply GCN\n",
    "            x = self.conv_GCN_input(data.x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            # x = self.conv_1_input(data.x, data.edge_index)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape) # [???, hidden_dim]\n",
    "            x = torch.nn.Dropout(p=0.5)(x)\n",
    "            x = self.conv_GCN_2(x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape)\n",
    "\n",
    "            processed_data.append(x)\n",
    "            processed_indices.append(indices)\n",
    "        \n",
    "        processed_data = torch.cat(processed_data, dim=0) \n",
    "        processed_indices = torch.cat(processed_indices, dim=0)\n",
    "        # print(processed_indices)\n",
    "        # print(processed_indices.argsort())\n",
    "        # print(processed_indices[processed_indices.argsort()])\n",
    "        processed_data = processed_data[processed_indices.argsort()] # ???????\n",
    "        processed_data = torch.split(processed_data, self.K) # ?????????\n",
    "        processed_data = torch.stack(list(processed_data), dim=0) # ???????????\n",
    "        # processed_data = torch.sum(list(processed_data), dim=0) # ???????????\n",
    "\n",
    "        # cat residual\n",
    "        processed_data = torch.cat((processed_data, feature_embedding.reshape((len(input_data),self.number_of_columns,-1))), dim=1) # [batch_size, K+cols , hidden_dim]\n",
    "        \n",
    "        # make prediction\n",
    "        prediction = self.prediction(processed_data.reshape(processed_data.shape[0],-1))\n",
    "        # prediction = self.prediction(feature_embedding)\n",
    "        \n",
    "        \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer.step()\n",
    "data_count = 5\n",
    "# random pick data\n",
    "indices = torch.randperm(len(x))[:data_count]\n",
    "train_data = x[indices]\n",
    "train_label = y[indices]\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = the_model(train_data[:data_count], epoch=200)\n",
    "    loss = torch.nn.functional.cross_entropy(output, train_label[:data_count])\n",
    "    loss.backward()\n",
    "    # print(((the_model.feature_importance_learners.grad).abs().max(dim=1)[0]))\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLP+FI.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "plot = torchviz.make_dot(loss, params=dict(the_model.named_parameters()))\n",
    "plot.render(\"MLP+FI\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, datas, batch_size, epoch):\n",
    "    train_data, train_label, validation_data, validation_label = datas\n",
    "    \n",
    "    # slice data into batch\n",
    "    train_data = torch.split(train_data, batch_size)\n",
    "    train_label = torch.split(train_label, batch_size)\n",
    "    validation_data = torch.split(validation_data, batch_size)\n",
    "    validation_label = torch.split(validation_label, batch_size)\n",
    "\n",
    "    # losses and metrics\n",
    "    batch_loss = 0\n",
    "    train_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    train_auc = BinaryAUROC().to(DEVICE)\n",
    "    valid_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    valid_auc = BinaryAUROC().to(DEVICE)\n",
    "    \n",
    "    # train the model\n",
    "    stepper = trange(len(train_data))\n",
    "    for i in stepper:\n",
    "        stepper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data[i], epoch=epoch)\n",
    "        loss = torch.nn.functional.cross_entropy(output, train_label[i]) * model.number_of_columns\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # metrics\n",
    "        preds = output.softmax(dim=1)\n",
    "        true = torch.nn.functional.one_hot(train_label[i], num_classes=2).to(DEVICE)\n",
    "        train_acc.update(torch.argmax(preds, 1),true.T[1])\n",
    "        train_auc.update(preds.T[0],true.T[0])\n",
    "        \n",
    "        # at the end of epoch, print result and validate the model\n",
    "        if i == len(train_data) - 1:\n",
    "            train_acc = train_acc.compute()\n",
    "            train_auc = train_auc.compute()\n",
    "            stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3)})\n",
    "            stepper.update()\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for i in range(len(validation_data)):\n",
    "                    output = model(validation_data[i], epoch=200)\n",
    "                    # loss = torch.nn.functional.cross_entropy(output, validation_label[i])\n",
    "                    preds = output.softmax(dim=1)\n",
    "                    true = torch.nn.functional.one_hot(validation_label[i], num_classes=2).to(DEVICE)\n",
    "                    valid_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "                    valid_auc.update(preds.T[0],true.T[0])\n",
    "                stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3), 'val_acc': round(valid_acc.compute().item(), 3), 'val_AUC': round(valid_auc.compute().item(), 3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_train(x, y, seed=0):\n",
    "    # hyperparameter\n",
    "    epoch = 50\n",
    "    batch_size = 1000\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # shuffle data\n",
    "    indices = torch.randperm(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    # slice data into train and test and validation\n",
    "    train_ratio = 0.7\n",
    "    validation_ratio = 0.1\n",
    "    train_data = x[:int(len(x)*train_ratio)]\n",
    "    train_label = y[:int(len(x)*train_ratio)]\n",
    "    validation_data = x[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    validation_label = y[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    test_data = x[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "    test_label = y[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "\n",
    "    # build model and optimizer\n",
    "    the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # train the model\n",
    "    datas = (train_data, train_label, validation_data, validation_label)\n",
    "    for i in range(epoch):\n",
    "        train_epoch(the_model, optimizer, datas, batch_size, epoch=i+1)\n",
    "        print(extractor.get())\n",
    "        extractor.reset()\n",
    "    \n",
    "    # test the model\n",
    "    with torch.no_grad():\n",
    "        test_data = torch.split(test_data, batch_size)\n",
    "        test_label = torch.split(test_label, batch_size)\n",
    "        for i in range(len(test_data)):\n",
    "            output = the_model(test_data[i], epoch=200)\n",
    "            preds = output.softmax(dim=1)\n",
    "            true = torch.nn.functional.one_hot(test_label[i], num_classes=2).to(DEVICE)\n",
    "            test_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "            test_auc = BinaryAUROC().to(DEVICE)\n",
    "            test_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "            test_auc.update(preds.T[0],true.T[0])\n",
    "\n",
    "        print('test_acc:', test_acc.compute().item())\n",
    "        print('test_auc:', test_auc.compute().item())\n",
    "        print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 35/35 [00:04<00:00,  8.40it/s, loss=43.4, acc=0.78, AUC=0.802, val_acc=0.824, val_AUC=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6158,  0.4862, -0.3629, -0.5126,  0.2436,  0.2867, -0.3363, -0.3433,\n",
      "         0.0320, -0.0995,  0.0014,  0.3815,  0.9984, -0.1594], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 35/35 [00:04<00:00,  8.71it/s, loss=34.3, acc=0.835, AUC=0.884, val_acc=0.831, val_AUC=0.893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.8969,  0.4658, -0.7856, -0.6236,  0.2363,  0.2527, -0.2119, -0.3694,\n",
      "        -0.0438, -0.0415,  0.0961,  0.6376,  1.1630,  0.1212], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 35/35 [00:03<00:00,  9.18it/s, loss=32.9, acc=0.844, AUC=0.894, val_acc=0.843, val_AUC=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9682,  0.4335, -0.9045, -0.4166,  0.3172,  0.1491, -0.1696, -0.3776,\n",
      "        -0.0901, -0.0327,  0.1213,  0.5759,  1.1719,  0.1905], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 35/35 [00:03<00:00,  8.81it/s, loss=32.2, acc=0.846, AUC=0.899, val_acc=0.845, val_AUC=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0442,  0.4291, -0.9681, -0.3003,  0.3534,  0.1060, -0.1519, -0.3845,\n",
      "        -0.1191, -0.0416,  0.1807,  0.5464,  1.1755,  0.2186], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 35/35 [00:03<00:00,  9.05it/s, loss=31.8, acc=0.851, AUC=0.902, val_acc=0.839, val_AUC=0.901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0865,  0.4205, -1.0094, -0.2468,  0.3537,  0.0775, -0.1309, -0.3836,\n",
      "        -0.1009, -0.0452,  0.2285,  0.5215,  1.1726,  0.2289], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 35/35 [00:03<00:00,  9.05it/s, loss=31.4, acc=0.852, AUC=0.904, val_acc=0.84, val_AUC=0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0903,  0.4269, -1.0458, -0.1562,  0.3534,  0.0542, -0.1180, -0.3705,\n",
      "        -0.1130, -0.0452,  0.2465,  0.4706,  1.1678,  0.2197], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 35/35 [00:03<00:00,  9.02it/s, loss=31, acc=0.853, AUC=0.907, val_acc=0.841, val_AUC=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1039,  0.4377, -1.0676, -0.0884,  0.3922,  0.0096, -0.1211, -0.3630,\n",
      "        -0.1190, -0.0506,  0.2609,  0.4651,  1.1306,  0.2175], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 35/35 [00:03<00:00,  9.00it/s, loss=31, acc=0.853, AUC=0.907, val_acc=0.846, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1277,  0.4405, -1.0762, -0.0086,  0.4018, -0.0081, -0.1252, -0.3633,\n",
      "        -0.1238, -0.0412,  0.2644,  0.4550,  1.1041,  0.2082], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 35/35 [00:03<00:00,  9.02it/s, loss=30.9, acc=0.853, AUC=0.907, val_acc=0.848, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1453,  0.4240, -1.0866,  0.0724,  0.3756, -0.0113, -0.1276, -0.3650,\n",
      "        -0.1102, -0.0330,  0.2739,  0.4305,  1.0754,  0.2271], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 35/35 [00:03<00:00,  9.02it/s, loss=30.7, acc=0.856, AUC=0.909, val_acc=0.844, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1458,  0.4296, -1.0964,  0.1361,  0.3657, -0.0170, -0.1409, -0.3617,\n",
      "        -0.1195, -0.0320,  0.2788,  0.4068,  1.0608,  0.2354], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 35/35 [00:03<00:00,  8.99it/s, loss=30.6, acc=0.856, AUC=0.909, val_acc=0.842, val_AUC=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1448,  0.4272, -1.1043,  0.1865,  0.3421, -0.0341, -0.1525, -0.3629,\n",
      "        -0.1313, -0.0208,  0.2730,  0.4086,  1.0634,  0.2500], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 35/35 [00:03<00:00,  8.98it/s, loss=30.5, acc=0.856, AUC=0.91, val_acc=0.846, val_AUC=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1515,  0.4046, -1.1287,  0.2105,  0.3363, -0.0411, -0.1407, -0.3556,\n",
      "        -0.1289, -0.0176,  0.2835,  0.4066,  1.0606,  0.2621], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 35/35 [00:03<00:00,  8.96it/s, loss=30.6, acc=0.856, AUC=0.91, val_acc=0.846, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1495,  0.3901, -1.1323,  0.2453,  0.3434, -0.0477, -0.1427, -0.3595,\n",
      "        -0.1386, -0.0245,  0.2859,  0.4102,  1.0651,  0.2548], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 35/35 [00:03<00:00,  8.93it/s, loss=30.4, acc=0.856, AUC=0.911, val_acc=0.845, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1648,  0.3909, -1.1483,  0.2859,  0.3548, -0.0643, -0.1242, -0.3721,\n",
      "        -0.1376, -0.0241,  0.2873,  0.4327,  1.0405,  0.2432], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 35/35 [00:03<00:00,  8.92it/s, loss=30.2, acc=0.857, AUC=0.912, val_acc=0.848, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1699,  0.3921, -1.1505,  0.3263,  0.3547, -0.0785, -0.1226, -0.3715,\n",
      "        -0.1473, -0.0199,  0.2809,  0.4286,  1.0221,  0.2556], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 35/35 [00:03<00:00,  8.81it/s, loss=30.2, acc=0.858, AUC=0.912, val_acc=0.846, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1683,  0.4005, -1.1619,  0.3542,  0.3476, -0.0877, -0.1155, -0.3805,\n",
      "        -0.1436, -0.0208,  0.2696,  0.4317,  1.0034,  0.2713], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 35/35 [00:03<00:00,  8.90it/s, loss=30.2, acc=0.857, AUC=0.912, val_acc=0.845, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1723,  0.4228, -1.1593,  0.3655,  0.3470, -0.0798, -0.1318, -0.3769,\n",
      "        -0.1495, -0.0167,  0.2597,  0.4220,  0.9997,  0.2697], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 35/35 [00:03<00:00,  8.88it/s, loss=30.2, acc=0.858, AUC=0.912, val_acc=0.848, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1789,  0.4127, -1.1594,  0.4075,  0.3418, -0.0669, -0.1374, -0.3809,\n",
      "        -0.1447, -0.0162,  0.2533,  0.4187,  1.0137,  0.2368], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 35/35 [00:03<00:00,  8.87it/s, loss=29.9, acc=0.858, AUC=0.913, val_acc=0.843, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1833,  0.4117, -1.1693,  0.4176,  0.3356, -0.0591, -0.1359, -0.3836,\n",
      "        -0.1347, -0.0198,  0.2520,  0.4155,  1.0184,  0.2349], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 35/35 [00:03<00:00,  8.86it/s, loss=30, acc=0.857, AUC=0.913, val_acc=0.847, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1821,  0.4153, -1.1741,  0.4390,  0.3306, -0.0493, -0.1469, -0.3996,\n",
      "        -0.1200, -0.0239,  0.2603,  0.4146,  1.0015,  0.2346], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 35/35 [00:03<00:00,  8.86it/s, loss=29.9, acc=0.859, AUC=0.913, val_acc=0.846, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1849,  0.4171, -1.1683,  0.4758,  0.3224, -0.0484, -0.1567, -0.4032,\n",
      "        -0.1102, -0.0307,  0.2639,  0.4063,  0.9809,  0.2359], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 35/35 [00:03<00:00,  8.83it/s, loss=29.9, acc=0.86, AUC=0.913, val_acc=0.852, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1979,  0.4235, -1.1745,  0.4800,  0.3259, -0.0350, -0.1723, -0.4130,\n",
      "        -0.0797, -0.0316,  0.2688,  0.3994,  0.9798,  0.2266], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 35/35 [00:03<00:00,  8.83it/s, loss=29.8, acc=0.858, AUC=0.914, val_acc=0.847, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1913,  0.4137, -1.1691,  0.4691,  0.3240, -0.0457, -0.1554, -0.4147,\n",
      "        -0.0948, -0.0306,  0.2598,  0.3911,  0.9975,  0.2464], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 35/35 [00:03<00:00,  8.84it/s, loss=29.8, acc=0.86, AUC=0.914, val_acc=0.849, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2018,  0.4094, -1.1601,  0.4749,  0.3122, -0.0478, -0.1607, -0.4134,\n",
      "        -0.0823, -0.0312,  0.2645,  0.3931,  0.9877,  0.2557], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 35/35 [00:04<00:00,  8.73it/s, loss=29.9, acc=0.859, AUC=0.914, val_acc=0.848, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1896,  0.4071, -1.1402,  0.4873,  0.3023, -0.0411, -0.1922, -0.4130,\n",
      "        -0.0878, -0.0315,  0.2533,  0.3945,  0.9935,  0.2573], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 35/35 [00:03<00:00,  8.83it/s, loss=29.8, acc=0.86, AUC=0.914, val_acc=0.848, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1939,  0.4144, -1.1435,  0.5060,  0.2860, -0.0373, -0.1771, -0.4162,\n",
      "        -0.0758, -0.0350,  0.2620,  0.3815,  0.9877,  0.2412], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 35/35 [00:03<00:00,  8.83it/s, loss=29.7, acc=0.86, AUC=0.914, val_acc=0.847, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2031,  0.4157, -1.1363,  0.5145,  0.2767, -0.0329, -0.1725, -0.4277,\n",
      "        -0.0726, -0.0387,  0.2722,  0.3786,  0.9789,  0.2473], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 35/35 [00:03<00:00,  8.83it/s, loss=29.7, acc=0.86, AUC=0.914, val_acc=0.849, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2019,  0.4149, -1.1322,  0.5150,  0.2813, -0.0299, -0.1825, -0.4224,\n",
      "        -0.0833, -0.0439,  0.2704,  0.3902,  0.9659,  0.2582], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 35/35 [00:03<00:00,  8.82it/s, loss=29.7, acc=0.859, AUC=0.915, val_acc=0.85, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2037,  0.4085, -1.1272,  0.5316,  0.2873, -0.0347, -0.1998, -0.4233,\n",
      "        -0.0820, -0.0440,  0.2626,  0.3824,  0.9568,  0.2855], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 35/35 [00:03<00:00,  8.81it/s, loss=29.7, acc=0.86, AUC=0.915, val_acc=0.854, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2088,  0.4188, -1.1119,  0.5294,  0.2807, -0.0327, -0.2212, -0.4182,\n",
      "        -0.0913, -0.0432,  0.2620,  0.3906,  0.9412,  0.3047], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 35/35 [00:03<00:00,  8.79it/s, loss=29.6, acc=0.859, AUC=0.915, val_acc=0.844, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2004,  0.4160, -1.1035,  0.5517,  0.2679, -0.0350, -0.2417, -0.4187,\n",
      "        -0.0926, -0.0414,  0.2657,  0.3908,  0.9371,  0.3041], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 35/35 [00:03<00:00,  8.78it/s, loss=29.7, acc=0.86, AUC=0.915, val_acc=0.848, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2078,  0.4232, -1.0935,  0.5624,  0.2636, -0.0404, -0.2416, -0.4252,\n",
      "        -0.0960, -0.0448,  0.2754,  0.3837,  0.9346,  0.3065], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 35/35 [00:03<00:00,  8.77it/s, loss=29.6, acc=0.861, AUC=0.915, val_acc=0.848, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2167,  0.4206, -1.1041,  0.5710,  0.2681, -0.0364, -0.2605, -0.4228,\n",
      "        -0.0782, -0.0477,  0.2801,  0.3894,  0.9337,  0.3036], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 35/35 [00:03<00:00,  8.77it/s, loss=29.5, acc=0.86, AUC=0.916, val_acc=0.849, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2082,  0.4364, -1.1070,  0.5737,  0.2726, -0.0508, -0.2726, -0.4234,\n",
      "        -0.0787, -0.0401,  0.2930,  0.3911,  0.9284,  0.2857], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 35/35 [00:04<00:00,  8.74it/s, loss=29.4, acc=0.862, AUC=0.916, val_acc=0.849, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1978,  0.4475, -1.1051,  0.5816,  0.2674, -0.0521, -0.2853, -0.4212,\n",
      "        -0.0691, -0.0436,  0.2849,  0.3927,  0.9265,  0.2736], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 35/35 [00:04<00:00,  8.73it/s, loss=29.4, acc=0.86, AUC=0.916, val_acc=0.852, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1943,  0.4423, -1.1036,  0.5806,  0.2782, -0.0454, -0.3097, -0.4236,\n",
      "        -0.0673, -0.0449,  0.2780,  0.4134,  0.9296,  0.2667], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 35/35 [00:04<00:00,  8.72it/s, loss=29.4, acc=0.862, AUC=0.916, val_acc=0.847, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2052,  0.4468, -1.1026,  0.5900,  0.2704, -0.0425, -0.3095, -0.4292,\n",
      "        -0.0517, -0.0477,  0.2863,  0.4191,  0.9151,  0.2608], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 35/35 [00:04<00:00,  8.72it/s, loss=29.4, acc=0.861, AUC=0.916, val_acc=0.846, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2096,  0.4585, -1.0989,  0.5963,  0.2667, -0.0359, -0.3063, -0.4268,\n",
      "        -0.0487, -0.0464,  0.2813,  0.4085,  0.9092,  0.2522], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 35/35 [00:04<00:00,  8.73it/s, loss=29.3, acc=0.86, AUC=0.917, val_acc=0.851, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2199,  0.4499, -1.0993,  0.5960,  0.2775, -0.0346, -0.3100, -0.4294,\n",
      "        -0.0457, -0.0454,  0.2828,  0.4104,  0.9097,  0.2582], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 35/35 [00:04<00:00,  8.72it/s, loss=29.3, acc=0.862, AUC=0.917, val_acc=0.852, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2150,  0.4558, -1.1030,  0.5853,  0.2873, -0.0344, -0.3198, -0.4323,\n",
      "        -0.0430, -0.0524,  0.2843,  0.4060,  0.9104,  0.2708], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 35/35 [00:04<00:00,  8.71it/s, loss=29.3, acc=0.861, AUC=0.917, val_acc=0.849, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2202,  0.4512, -1.1100,  0.5786,  0.2907, -0.0395, -0.3102, -0.4330,\n",
      "        -0.0360, -0.0529,  0.2876,  0.4102,  0.9091,  0.2744], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 35/35 [00:04<00:00,  8.61it/s, loss=29.2, acc=0.86, AUC=0.917, val_acc=0.849, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2207,  0.4612, -1.0952,  0.5925,  0.2931, -0.0456, -0.3158, -0.4332,\n",
      "        -0.0483, -0.0567,  0.2834,  0.3995,  0.9119,  0.2740], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 35/35 [00:04<00:00,  8.70it/s, loss=29.3, acc=0.86, AUC=0.917, val_acc=0.849, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2259,  0.4592, -1.0840,  0.5915,  0.2992, -0.0510, -0.3248, -0.4399,\n",
      "        -0.0441, -0.0540,  0.2807,  0.4088,  0.9090,  0.2752], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 35/35 [00:04<00:00,  8.69it/s, loss=29.3, acc=0.861, AUC=0.917, val_acc=0.85, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2185,  0.4583, -1.0799,  0.5862,  0.2964, -0.0539, -0.3419, -0.4373,\n",
      "        -0.0476, -0.0548,  0.2771,  0.4135,  0.9193,  0.2831], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 35/35 [00:04<00:00,  8.69it/s, loss=29.3, acc=0.861, AUC=0.917, val_acc=0.847, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2238,  0.4581, -1.0797,  0.5832,  0.2901, -0.0619, -0.3377, -0.4371,\n",
      "        -0.0414, -0.0557,  0.2777,  0.4168,  0.9198,  0.2917], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 35/35 [00:04<00:00,  8.68it/s, loss=29.2, acc=0.861, AUC=0.918, val_acc=0.847, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2205,  0.4493, -1.0731,  0.5964,  0.2811, -0.0743, -0.3351, -0.4437,\n",
      "        -0.0370, -0.0611,  0.2774,  0.4024,  0.9320,  0.3061], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 35/35 [00:04<00:00,  8.69it/s, loss=29.1, acc=0.862, AUC=0.918, val_acc=0.847, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2146,  0.4569, -1.0602,  0.6150,  0.2879, -0.0750, -0.3490, -0.4417,\n",
      "        -0.0427, -0.0628,  0.2668,  0.3960,  0.9147,  0.3086], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 35/35 [00:04<00:00,  8.68it/s, loss=29.2, acc=0.863, AUC=0.918, val_acc=0.85, val_AUC=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2143,  0.4476, -1.0602,  0.6178,  0.2960, -0.0762, -0.3455, -0.4459,\n",
      "        -0.0381, -0.0652,  0.2724,  0.3961,  0.9107,  0.3047], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 35/35 [00:04<00:00,  8.68it/s, loss=29, acc=0.862, AUC=0.918, val_acc=0.847, val_AUC=0.91]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2245,  0.4541, -1.0634,  0.6016,  0.3044, -0.0656, -0.3535, -0.4488,\n",
      "        -0.0321, -0.0665,  0.2744,  0.4052,  0.9055,  0.3092], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 35/35 [00:04<00:00,  8.68it/s, loss=29, acc=0.863, AUC=0.919, val_acc=0.85, val_AUC=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.2277,  0.4556, -1.0590,  0.6082,  0.2961, -0.0565, -0.3593, -0.4456,\n",
      "        -0.0222, -0.0700,  0.2779,  0.4021,  0.8951,  0.3054], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n",
      "test_acc: 0.8543562889099121\n",
      "test_auc: 0.9134344345472996\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seed_set = [9,90,900,9000,90000]\n",
    "overall_train(x, y, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155015230178833"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7051671743392944,\n",
    "     0.7082067131996155,\n",
    "     0.7051671743392944,\n",
    "     0.7264437675476074,\n",
    "     0.7325227856636047\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940417876933872"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7808573540280858,\n",
    "     0.7863905325443787,\n",
    "     0.7797353553374963,\n",
    "     0.8075237670825907,\n",
    "     0.8157019294743846\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
