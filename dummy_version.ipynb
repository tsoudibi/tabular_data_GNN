{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/pyg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import seed_everything\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import torch_geometric\n",
    "from tqdm import tqdm, trange\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cuda')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16644, 17]) torch.Size([16644])\n",
      "[2, 3, 6, 13, 10, 3, 1, 10, 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>is_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.763142</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>0.360236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277735</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-1.493342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.069224</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.030074</td>\n",
       "      <td>-0.744908</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>1.034535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884913</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.030074</td>\n",
       "      <td>-0.190846</td>\n",
       "      <td>-0.118240</td>\n",
       "      <td>0.366177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.849881</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>7.344876</td>\n",
       "      <td>-0.584398</td>\n",
       "      <td>-0.350908</td>\n",
       "      <td>-0.069329</td>\n",
       "      <td>1.287026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>-1.110101</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>1.319701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16640</th>\n",
       "      <td>-0.329443</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-0.245741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16641</th>\n",
       "      <td>-0.329443</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>0.235476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16642</th>\n",
       "      <td>-0.936621</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.080033</td>\n",
       "      <td>-0.152102</td>\n",
       "      <td>-1.053711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16643</th>\n",
       "      <td>-0.936621</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.080033</td>\n",
       "      <td>-0.152102</td>\n",
       "      <td>0.083982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16644 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0     -0.763142       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "1      0.277735       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "2     -0.069224       -0.17116       -0.195994        -0.249708     -0.030074   \n",
       "3      0.884913       -0.17116       -0.195994        -0.249708     -0.030074   \n",
       "4     -0.849881       -0.17116       -0.195994         7.344876     -0.584398   \n",
       "...         ...            ...             ...              ...           ...   \n",
       "16639 -1.110101       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16640 -0.329443       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16641 -0.329443       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16642 -0.936621       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "16643 -0.936621       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "\n",
       "       days_b_screening_arrest  c_days_from_compas       end  sex  age_cat  \\\n",
       "0                    -0.067721           -0.155864  0.360236  1.0      0.0   \n",
       "1                    -0.067721           -0.155864 -1.493342  0.0      0.0   \n",
       "2                    -0.744908            0.051069  1.034535  1.0      0.0   \n",
       "3                    -0.190846           -0.118240  0.366177  0.0      0.0   \n",
       "4                    -0.350908           -0.069329  1.287026  0.0      2.0   \n",
       "...                        ...                 ...       ...  ...      ...   \n",
       "16639                -0.067721           -0.155864  1.319701  1.0      2.0   \n",
       "16640                -0.067721           -0.155864 -0.245741  1.0      0.0   \n",
       "16641                -0.067721           -0.155864  0.235476  1.0      0.0   \n",
       "16642                -0.080033           -0.152102 -1.053711  0.0      2.0   \n",
       "16643                -0.080033           -0.152102  0.083982  0.0      2.0   \n",
       "\n",
       "       race  c_charge_degree  decile_score.1  score_text  \\\n",
       "0       0.0              3.0             3.0         1.0   \n",
       "1       2.0              2.0             4.0         2.0   \n",
       "2       2.0              6.0             5.0         2.0   \n",
       "3       2.0              2.0             3.0         1.0   \n",
       "4       2.0              7.0             3.0         1.0   \n",
       "...     ...              ...             ...         ...   \n",
       "16639   2.0              7.0             5.0         2.0   \n",
       "16640   0.0              7.0             1.0         1.0   \n",
       "16641   0.0              7.0             1.0         1.0   \n",
       "16642   3.0              3.0             3.0         1.0   \n",
       "16643   3.0              3.0             3.0         1.0   \n",
       "\n",
       "       v_type_of_assessment  v_decile_score  v_score_text  is_recid  \n",
       "0                       0.0             3.0           1.0         0  \n",
       "1                       0.0             1.0           1.0         0  \n",
       "2                       0.0             4.0           2.0         0  \n",
       "3                       0.0             1.0           1.0         0  \n",
       "4                       0.0             3.0           1.0         0  \n",
       "...                     ...             ...           ...       ...  \n",
       "16639                   0.0             6.0           2.0         1  \n",
       "16640                   0.0             1.0           1.0         1  \n",
       "16641                   0.0             1.0           1.0         1  \n",
       "16642                   0.0             3.0           1.0         1  \n",
       "16643                   0.0             3.0           1.0         1  \n",
       "\n",
       "[16644 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature from csv\n",
    "RAW_data = pd.read_csv('data/adult.csv')\n",
    "CAT = ['workclass','education','marital-status','occupation','relationship','race','gender','native-country']\n",
    "NUM = ['age','fnlwgt','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "LABEL = 'income'\n",
    "# RAW_data = pd.read_csv('data/compass_old.csv')\n",
    "# CAT=['sex','age_cat','race','c_charge_degree','decile_score.1','score_text','v_type_of_assessment','v_decile_score','v_score_text']\n",
    "# NUM=['age','juv_fel_count','juv_misd_count','juv_other_count','priors_count','days_b_screening_arrest','c_days_from_compas','end']\n",
    "# LABEL = 'is_recid'\n",
    "# convert categorical data to ordinal data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "data_pd = RAW_data.copy()\n",
    "data_pd[CAT] = enc.fit_transform(RAW_data[CAT])\n",
    "# data_pd = pd.get_dummies(RAW_data, columns=CAT, dtype=float)\n",
    "# label to category\n",
    "data_pd[LABEL] = data_pd[LABEL].astype('category').cat.codes\n",
    "\n",
    "# realign data to num + cat\n",
    "data_pd = data_pd[NUM + CAT + [LABEL]]\n",
    "\n",
    "# caculate unique value of each categorical feature\n",
    "cat_num = [len(data_pd[col].unique()) for col in CAT]\n",
    "\n",
    "# normalize numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_pd[NUM] = scaler.fit_transform(data_pd[NUM])\n",
    "\n",
    "# convert data to tensor\n",
    "x = torch.tensor(data_pd.drop(columns=[LABEL]).values, dtype=torch.float, device=DEVICE)  # [48842, 108]\n",
    "y = torch.tensor(data_pd[LABEL].values, dtype=torch.long, device=DEVICE) # [48842]\n",
    "print(x.shape, y.shape)\n",
    "print(cat_num)\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_improtance_extractor():\n",
    "    def __init__(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        pass\n",
    "    def update(self, new_feature_importance):\n",
    "        if self.iter == 0:\n",
    "            self.feature_importance = new_feature_importance\n",
    "        else:\n",
    "            self.feature_importance += new_feature_importance\n",
    "        self.iter += 1\n",
    "        return\n",
    "    \n",
    "    def get(self):\n",
    "        return (self.feature_importance / self.iter)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        return\n",
    "extractor = feature_improtance_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_graph(torch.nn.Module):\n",
    "    def __init__(self, NUM, CAT, LABEL, cat_num):\n",
    "        super(K_graph, self).__init__()\n",
    "        '''\n",
    "        num_cols: number of numerical columns\n",
    "        cat_cols: number of categorical columns\n",
    "        label_cols: number of label columns\n",
    "        cat_num: number of unique value of each categorical columns\n",
    "        '''\n",
    "        self.hidden_dim = 128\n",
    "        # order: num -> cat -> label\n",
    "        self.num_cols = len(NUM)\n",
    "        self.cat_cols = len(CAT)\n",
    "        self.label_cols = len(LABEL)\n",
    "        self.number_of_columns = self.num_cols + self.cat_cols \n",
    "        self.K = round(self.number_of_columns*0.5)\n",
    "        \n",
    "        # numerical feature\n",
    "        self.num_embeddings = torch.nn.ModuleList([torch.nn.Linear(1, self.hidden_dim) for i in range(self.num_cols)])\n",
    "        # categorical feature\n",
    "        self.cat_embeddings = torch.nn.ModuleList([torch.nn.Embedding(cat_num[i], self.hidden_dim) for i in range(self.cat_cols)])\n",
    "        \n",
    "        self.prediction = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim *( self.K + self.number_of_columns), self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Linear(self.hidden_dim, self.label_cols + 1)\n",
    "        )\n",
    "        \n",
    "        # feature importance learning\n",
    "        self.feature_importance_learners = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        ) \n",
    "        \n",
    "        # graph convolution layers\n",
    "        self.conv_GCN_input = torch_geometric.nn.GCNConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_GCN_input = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_1_input = torch_geometric.nn.GATConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        self.conv_GCN_2 = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        # self.transform = torch.nn.Linear(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, input_data, epoch = -1):\n",
    "        \n",
    "        # make feature embedding\n",
    "        num_data = input_data[:,:self.num_cols].unsqueeze(-1).unsqueeze(-1) \n",
    "        feature_embedding_num = torch.cat([self.num_embeddings[i](num_data[:,i]) for i in range(self.num_cols)], dim=1).reshape(len(input_data), -1) # [batch_size, num_cols * hidden_dim]\n",
    "        feature_embedding_num = torch.nn.ReLU()(feature_embedding_num)\n",
    "        feature_embedding_num = torch.layer_norm(feature_embedding_num, feature_embedding_num.shape)\n",
    "        # categorical feature\n",
    "        feature_embedding_cat = torch.cat([self.cat_embeddings[i](input_data[:,self.num_cols+i].long()) for i in range(self.cat_cols)], dim=1) # [batch_size, cat_cols * hidden_dim]\n",
    "        feature_embedding_cat = torch.layer_norm(feature_embedding_cat, feature_embedding_cat.shape)\n",
    "        # concat\n",
    "        feature_embedding = torch.cat((feature_embedding_num, feature_embedding_cat), dim=1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        # feature_embedding = feature_embedding.reshape((len(input_data), self.number_of_columns, -1)) # [batch_size, (num_cols + cat_cols), hidden_dim]\n",
    "        \n",
    "        # feature importance learning\n",
    "        feature_importance = torch.cat([self.feature_importance_learners(feature_embedding[:,i*self.hidden_dim:(i+1)*self.hidden_dim]) for i in range(self.number_of_columns)], dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance)\n",
    "        feature_importance = torch.layer_norm(feature_importance, feature_importance.shape)\n",
    "        # feature_importance = torch.softmax(feature_importance, dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance.shape)\n",
    "        # print(feature_importance.sum(dim=1))\n",
    "        # print(feature_importance)\n",
    "        \n",
    "        # weighted feature embedding \n",
    "        feature_embedding = feature_embedding.reshape((len(input_data),self.number_of_columns, -1)) * feature_importance.unsqueeze(-1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        feature_embedding = feature_embedding.reshape((len(input_data), -1)) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        \n",
    "        # top K feature importance\n",
    "        K = self.K\n",
    "        value, indices = torch.topk(feature_importance, K) # (value: [batch_size, k], indices: [batch_size, k])\n",
    "        mask = torch.zeros_like(feature_importance, device=DEVICE)\n",
    "        mask.scatter_(1, indices, 1)\n",
    "        # importance_topK = torch.where(mask > 0, feature_importance, torch.zeros(feature_importance.shape,device=DEVICE)) # [batch_size, cols]\n",
    "        importance_topK = torch.where(mask > 0, feature_importance, torch.empty(feature_importance.shape,device=DEVICE).fill_(-1e9)) # [batch_size, cols]\n",
    "        importance_topK = torch.softmax(importance_topK, dim=1) # [batch_size, cols]\n",
    "        # importance_topK = torch.stack([importance_topK.clone() for _ in range(self.number_of_columns)], dim=0) # [cols, batch_size, cols]\n",
    "        \n",
    "        extractor.update(feature_importance.sum(dim=0)/len(input_data))\n",
    "        del feature_embedding_num, feature_embedding_cat, num_data\n",
    "        del mask, feature_importance, value, indices\n",
    "        \n",
    "        \n",
    "        processed_data = []\n",
    "        processed_indices = []\n",
    "        for target_col in range(self.number_of_columns):\n",
    "            importance_topK_current = importance_topK.clone()# [batch_size, cols] \n",
    "            indices = importance_topK_current.T[target_col].nonzero().T[0] # selected samples' indices  \n",
    "            \n",
    "            if indices.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            importance_topK_current = importance_topK_current[importance_topK_current.T[target_col]>0]# [????, cols]\n",
    "            \n",
    "            # for target column, set its importance to 0. so that it will not be fully connected graph\n",
    "            # copy target column\n",
    "            tmp = torch.clone(importance_topK_current[:,target_col]) # [????], save for future weighted sum\n",
    "            importance_topK_current[:,target_col] = 0 # [????, cols]\n",
    "            # multiply to get weighted adj\n",
    "            weighted_adj = torch.matmul(importance_topK_current, importance_topK_current.T) # [batch_size, cols] * [cols, batch_size] = [batch_size, batch_size]\n",
    "            # prune the diagonal\n",
    "            weighted_adj = weighted_adj - torch.diag(weighted_adj.diagonal())\n",
    "\n",
    "            # construct graph\n",
    "            edge_index = weighted_adj.nonzero().T  # [2, num_edges]\n",
    "            edge_wight = weighted_adj[edge_index[0], edge_index[1]] # [num_edges]\n",
    "            edge_wight = torch.softmax(edge_wight, dim=0)\n",
    "\n",
    "            \n",
    "            if False:\n",
    "                print('in graph', target_col, 'nodes:', len(indices), 'edges:', len(edge_wight),'ratio', len(edge_wight)/(len(indices)**2+0.000001))\n",
    "            \n",
    "            # print(edge_wight)\n",
    "            # importance_topK_current[:,target_col] = tmp # [????, cols]\n",
    "            \n",
    "            features = (feature_embedding[indices]) # [????, cols*hidden_dim]\n",
    "            # features = (feature_embedding.reshape(len(input_data),self.number_of_columns,-1)[indices][:,target_col,:]) # [????, hidden_dim]\n",
    "            # print(features.shape)\n",
    "\n",
    "            # construct graph \n",
    "            data = Data(x=features, edge_index=edge_index, edge_weight=edge_wight, indices=indices) \n",
    "            \n",
    "            del features, edge_index, edge_wight, weighted_adj, importance_topK_current, tmp\n",
    "            \n",
    "            # apply GCN\n",
    "            x = self.conv_GCN_input(data.x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            # x = self.conv_1_input(data.x, data.edge_index)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape) # [???, hidden_dim]\n",
    "            x = torch.nn.Dropout(p=0.5)(x)\n",
    "            x = self.conv_GCN_2(x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape)\n",
    "\n",
    "            processed_data.append(x)\n",
    "            processed_indices.append(indices)\n",
    "        \n",
    "        processed_data = torch.cat(processed_data, dim=0) \n",
    "        processed_indices = torch.cat(processed_indices, dim=0)\n",
    "        # print(processed_indices)\n",
    "        # print(processed_indices.argsort())\n",
    "        # print(processed_indices[processed_indices.argsort()])\n",
    "        processed_data = processed_data[processed_indices.argsort()] # ???????\n",
    "        processed_data = torch.split(processed_data, self.K) # ?????????\n",
    "        processed_data = torch.stack(list(processed_data), dim=0) # ???????????\n",
    "        # processed_data = torch.sum(list(processed_data), dim=0) # ???????????\n",
    "\n",
    "        # cat residual\n",
    "        processed_data = torch.cat((processed_data, feature_embedding.reshape((len(input_data),self.number_of_columns,-1))), dim=1) # [batch_size, K+cols , hidden_dim]\n",
    "        \n",
    "        # make prediction\n",
    "        prediction = self.prediction(processed_data.reshape(processed_data.shape[0],-1))\n",
    "        # prediction = self.prediction(feature_embedding)\n",
    "        \n",
    "        \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer.step()\n",
    "data_count = 5\n",
    "# random pick data\n",
    "indices = torch.randperm(len(x))[:data_count]\n",
    "train_data = x[indices]\n",
    "train_label = y[indices]\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = the_model(train_data[:data_count], epoch=200)\n",
    "    loss = torch.nn.functional.cross_entropy(output, train_label[:data_count])\n",
    "    loss.backward()\n",
    "    # print(((the_model.feature_importance_learners.grad).abs().max(dim=1)[0]))\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLP+FI.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "plot = torchviz.make_dot(loss, params=dict(the_model.named_parameters()))\n",
    "plot.render(\"MLP+FI\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, datas, batch_size, epoch):\n",
    "    train_data, train_label, validation_data, validation_label = datas\n",
    "    \n",
    "    # slice data into batch\n",
    "    train_data = torch.split(train_data, batch_size)\n",
    "    train_label = torch.split(train_label, batch_size)\n",
    "    validation_data = torch.split(validation_data, batch_size)\n",
    "    validation_label = torch.split(validation_label, batch_size)\n",
    "\n",
    "    # losses and metrics\n",
    "    batch_loss = 0\n",
    "    train_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    train_auc = BinaryAUROC().to(DEVICE)\n",
    "    valid_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    valid_auc = BinaryAUROC().to(DEVICE)\n",
    "    \n",
    "    # train the model\n",
    "    stepper = trange(len(train_data))\n",
    "    for i in stepper:\n",
    "        stepper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data[i], epoch=epoch)\n",
    "        loss = torch.nn.functional.cross_entropy(output, train_label[i]) * model.number_of_columns\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # metrics\n",
    "        preds = output.softmax(dim=1)\n",
    "        true = torch.nn.functional.one_hot(train_label[i], num_classes=2).to(DEVICE)\n",
    "        train_acc.update(torch.argmax(preds, 1),true.T[1])\n",
    "        train_auc.update(preds.T[0],true.T[0])\n",
    "        \n",
    "        # at the end of epoch, print result and validate the model\n",
    "        if i == len(train_data) - 1:\n",
    "            train_acc = train_acc.compute()\n",
    "            train_auc = train_auc.compute()\n",
    "            stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3)})\n",
    "            stepper.update()\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for i in range(len(validation_data)):\n",
    "                    output = model(validation_data[i], epoch=200)\n",
    "                    # loss = torch.nn.functional.cross_entropy(output, validation_label[i])\n",
    "                    preds = output.softmax(dim=1)\n",
    "                    true = torch.nn.functional.one_hot(validation_label[i], num_classes=2).to(DEVICE)\n",
    "                    valid_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "                    valid_auc.update(preds.T[0],true.T[0])\n",
    "                stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3), 'val_acc': round(valid_acc.compute().item(), 3), 'val_AUC': round(valid_auc.compute().item(), 3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_train(x, y, seed=0):\n",
    "    # hyperparameter\n",
    "    epoch = 50\n",
    "    batch_size = 1000\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # shuffle data\n",
    "    indices = torch.randperm(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    # slice data into train and test and validation\n",
    "    train_ratio = 0.7\n",
    "    validation_ratio = 0.1\n",
    "    train_data = x[:int(len(x)*train_ratio)]\n",
    "    train_label = y[:int(len(x)*train_ratio)]\n",
    "    validation_data = x[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    validation_label = y[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    test_data = x[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "    test_label = y[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "\n",
    "    # build model and optimizer\n",
    "    the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # train the model\n",
    "    datas = (train_data, train_label, validation_data, validation_label)\n",
    "    for i in range(epoch):\n",
    "        train_epoch(the_model, optimizer, datas, batch_size, epoch=i+1)\n",
    "        print(extractor.get())\n",
    "        extractor.reset()\n",
    "    \n",
    "    # test the model\n",
    "    with torch.no_grad():\n",
    "        test_data = torch.split(test_data, batch_size)\n",
    "        test_label = torch.split(test_label, batch_size)\n",
    "        for i in range(len(test_data)):\n",
    "            output = the_model(test_data[i], epoch=200)\n",
    "            preds = output.softmax(dim=1)\n",
    "            true = torch.nn.functional.one_hot(test_label[i], num_classes=2).to(DEVICE)\n",
    "            test_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "            test_auc = BinaryAUROC().to(DEVICE)\n",
    "            test_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "            test_auc.update(preds.T[0],true.T[0])\n",
    "\n",
    "        print('test_acc:', test_acc.compute().item())\n",
    "        print('test_auc:', test_auc.compute().item())\n",
    "        print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 12/12 [00:01<00:00,  7.07it/s, loss=71.2, acc=0.596, AUC=0.623, val_acc=0.661, val_AUC=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3221, -0.4679, -0.0602,  0.2983,  0.9280, -0.0398, -0.1949,  0.1321,\n",
      "        -0.4120,  0.2410, -0.6399, -0.4115, -0.0655,  0.3109,  0.0815,  0.1306,\n",
      "         0.4915], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 12/12 [00:01<00:00,  8.25it/s, loss=63.2, acc=0.662, AUC=0.717, val_acc=0.686, val_AUC=0.739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2745, -0.3226, -0.0417,  0.1941,  1.3277, -0.1570, -0.2210,  0.3619,\n",
      "        -0.3185,  0.2017, -0.7167, -0.3695, -0.2605,  0.3575, -0.2545,  0.0049,\n",
      "         0.4887], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 12/12 [00:01<00:00,  9.10it/s, loss=62.8, acc=0.671, AUC=0.724, val_acc=0.678, val_AUC=0.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3593, -0.3965, -0.0345,  0.1315,  1.4310, -0.1678, -0.1883,  0.3280,\n",
      "        -0.3274,  0.2149, -0.7271, -0.3078, -0.2558,  0.3378, -0.2106,  0.0192,\n",
      "         0.5127], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 12/12 [00:01<00:00,  9.11it/s, loss=61.7, acc=0.674, AUC=0.735, val_acc=0.687, val_AUC=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4173, -0.4115, -0.0149,  0.1460,  1.4899, -0.1977, -0.1427,  0.2747,\n",
      "        -0.3581,  0.2206, -0.6867, -0.2517, -0.2673,  0.2775, -0.2146,  0.0303,\n",
      "         0.5234], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 12/12 [00:01<00:00,  9.06it/s, loss=61.1, acc=0.684, AUC=0.743, val_acc=0.694, val_AUC=0.757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4393, -0.3805, -0.0185,  0.1541,  1.5450, -0.1916, -0.1670,  0.2665,\n",
      "        -0.3663,  0.2184, -0.7000, -0.2523, -0.2811,  0.2529, -0.2245,  0.0378,\n",
      "         0.5465], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 12/12 [00:01<00:00,  9.03it/s, loss=60.7, acc=0.687, AUC=0.747, val_acc=0.694, val_AUC=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4839, -0.4106,  0.0524,  0.1765,  1.5865, -0.2082, -0.1389,  0.2531,\n",
      "        -0.4075,  0.2320, -0.6639, -0.2649, -0.2950,  0.1964, -0.1837,  0.0307,\n",
      "         0.5291], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 12/12 [00:01<00:00,  8.97it/s, loss=60.8, acc=0.685, AUC=0.746, val_acc=0.696, val_AUC=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5108, -0.4545,  0.0987,  0.1855,  1.6209, -0.2137, -0.0909,  0.2361,\n",
      "        -0.4487,  0.2251, -0.6672, -0.2507, -0.2974,  0.1819, -0.1442,  0.0268,\n",
      "         0.5030], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 12/12 [00:01<00:00,  8.97it/s, loss=60.5, acc=0.687, AUC=0.75, val_acc=0.691, val_AUC=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5251, -0.4344,  0.1030,  0.1594,  1.6574, -0.2192, -0.0708,  0.2242,\n",
      "        -0.4679,  0.2501, -0.6787, -0.2709, -0.2889,  0.1893, -0.1633,  0.0329,\n",
      "         0.5030], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 12/12 [00:01<00:00,  8.93it/s, loss=60.2, acc=0.689, AUC=0.752, val_acc=0.693, val_AUC=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5337, -0.4026,  0.1071,  0.1632,  1.6738, -0.2116, -0.0569,  0.2224,\n",
      "        -0.5010,  0.2414, -0.6703, -0.2940, -0.2932,  0.1858, -0.1705,  0.0275,\n",
      "         0.5126], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 12/12 [00:01<00:00,  8.97it/s, loss=60, acc=0.695, AUC=0.756, val_acc=0.697, val_AUC=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5682, -0.3721,  0.1157,  0.1528,  1.6869, -0.2185, -0.0402,  0.1940,\n",
      "        -0.5420,  0.2367, -0.6292, -0.2836, -0.2936,  0.1568, -0.1299,  0.0230,\n",
      "         0.5117], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 12/12 [00:01<00:00,  8.93it/s, loss=60.2, acc=0.693, AUC=0.753, val_acc=0.696, val_AUC=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5730, -0.3434,  0.1156,  0.1415,  1.6963, -0.2443, -0.0390,  0.1987,\n",
      "        -0.5699,  0.2462, -0.6159, -0.2960, -0.2919,  0.1518, -0.1249,  0.0263,\n",
      "         0.5220], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 12/12 [00:01<00:00,  8.97it/s, loss=59.6, acc=0.697, AUC=0.759, val_acc=0.696, val_AUC=0.762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5920, -0.3394,  0.1001,  0.1077,  1.6967, -0.2499, -0.0262,  0.1893,\n",
      "        -0.5604,  0.2599, -0.6176, -0.2869, -0.2890,  0.1558, -0.1098,  0.0311,\n",
      "         0.5303], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 12/12 [00:01<00:00,  8.92it/s, loss=59.5, acc=0.695, AUC=0.76, val_acc=0.699, val_AUC=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5923, -0.3279,  0.1063,  0.0962,  1.7130, -0.2555, -0.0176,  0.1941,\n",
      "        -0.5838,  0.2771, -0.6192, -0.2981, -0.2827,  0.1392, -0.0853,  0.0241,\n",
      "         0.5123], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 12/12 [00:01<00:00,  8.93it/s, loss=59.7, acc=0.695, AUC=0.758, val_acc=0.687, val_AUC=0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5951, -0.2841,  0.0826,  0.0920,  1.7116, -0.2618, -0.0223,  0.2085,\n",
      "        -0.5697,  0.2937, -0.6273, -0.3017, -0.2827,  0.1347, -0.0947,  0.0197,\n",
      "         0.4966], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 12/12 [00:01<00:00,  8.91it/s, loss=59.6, acc=0.698, AUC=0.759, val_acc=0.702, val_AUC=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6028, -0.2780,  0.0821,  0.0854,  1.7378, -0.2660, -0.0162,  0.2088,\n",
      "        -0.5719,  0.2977, -0.6163, -0.3134, -0.2898,  0.1249, -0.1126,  0.0232,\n",
      "         0.5073], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 12/12 [00:01<00:00,  8.92it/s, loss=59.3, acc=0.701, AUC=0.763, val_acc=0.695, val_AUC=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5949, -0.2696,  0.0931,  0.0910,  1.7263, -0.2960, -0.0040,  0.1849,\n",
      "        -0.5649,  0.3011, -0.6202, -0.3075, -0.2872,  0.1131, -0.0806,  0.0241,\n",
      "         0.4915], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 12/12 [00:01<00:00,  8.84it/s, loss=59.3, acc=0.7, AUC=0.763, val_acc=0.702, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6309, -0.2950,  0.1159,  0.1078,  1.7343, -0.3143,  0.0211,  0.1738,\n",
      "        -0.5423,  0.3044, -0.6385, -0.3149, -0.2766,  0.1134, -0.0745,  0.0368,\n",
      "         0.4797], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 12/12 [00:01<00:00,  8.84it/s, loss=59.1, acc=0.701, AUC=0.765, val_acc=0.695, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6373, -0.2848,  0.1222,  0.1023,  1.7370, -0.3295,  0.0364,  0.1843,\n",
      "        -0.5265,  0.3124, -0.6544, -0.3333, -0.2884,  0.1065, -0.0659,  0.0284,\n",
      "         0.4907], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 12/12 [00:01<00:00,  8.86it/s, loss=59.1, acc=0.702, AUC=0.765, val_acc=0.698, val_AUC=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6297, -0.2625,  0.1261,  0.0888,  1.7414, -0.3421,  0.0426,  0.1920,\n",
      "        -0.5330,  0.3258, -0.6647, -0.3485, -0.2969,  0.1054, -0.0639,  0.0320,\n",
      "         0.4872], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 12/12 [00:01<00:00,  8.84it/s, loss=59.4, acc=0.697, AUC=0.762, val_acc=0.702, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6462, -0.2533,  0.1513,  0.0816,  1.7549, -0.3491,  0.0695,  0.1848,\n",
      "        -0.5527,  0.3369, -0.6618, -0.3438, -0.2938,  0.1038, -0.0763,  0.0282,\n",
      "         0.4659], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 12/12 [00:01<00:00,  8.79it/s, loss=59.1, acc=0.701, AUC=0.765, val_acc=0.705, val_AUC=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6631, -0.2486,  0.1753,  0.0992,  1.7540, -0.3572,  0.0664,  0.1781,\n",
      "        -0.5660,  0.3411, -0.6628, -0.3437, -0.2967,  0.0745, -0.0371,  0.0251,\n",
      "         0.4614], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 12/12 [00:01<00:00,  8.77it/s, loss=58.5, acc=0.703, AUC=0.771, val_acc=0.702, val_AUC=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6728, -0.2337,  0.1617,  0.1021,  1.7523, -0.3710,  0.0685,  0.1951,\n",
      "        -0.5737,  0.3502, -0.6728, -0.3574, -0.2888,  0.0742, -0.0299,  0.0373,\n",
      "         0.4586], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 12/12 [00:01<00:00,  8.52it/s, loss=58.8, acc=0.705, AUC=0.768, val_acc=0.705, val_AUC=0.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6698, -0.2316,  0.1756,  0.0954,  1.7530, -0.3743,  0.0868,  0.2045,\n",
      "        -0.5872,  0.3531, -0.6857, -0.3557, -0.2922,  0.0706, -0.0384,  0.0347,\n",
      "         0.4614], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 12/12 [00:01<00:00,  8.76it/s, loss=58.5, acc=0.704, AUC=0.771, val_acc=0.712, val_AUC=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6797, -0.2073,  0.1768,  0.0983,  1.7425, -0.3632,  0.0945,  0.2082,\n",
      "        -0.5862,  0.3461, -0.7059, -0.3547, -0.2958,  0.0606, -0.0246,  0.0337,\n",
      "         0.4567], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 12/12 [00:01<00:00,  8.75it/s, loss=58.9, acc=0.701, AUC=0.766, val_acc=0.713, val_AUC=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6848, -0.1858,  0.1826,  0.0864,  1.7362, -0.3630,  0.1186,  0.2035,\n",
      "        -0.5851,  0.3598, -0.7101, -0.3509, -0.3095,  0.0380, -0.0199,  0.0288,\n",
      "         0.4554], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 12/12 [00:01<00:00,  8.73it/s, loss=58.5, acc=0.707, AUC=0.77, val_acc=0.695, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6742, -0.1664,  0.1777,  0.0695,  1.7296, -0.3725,  0.1287,  0.2109,\n",
      "        -0.5853,  0.3520, -0.7187, -0.3376, -0.3038,  0.0288, -0.0245,  0.0216,\n",
      "         0.4639], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 12/12 [00:01<00:00,  8.73it/s, loss=58.4, acc=0.705, AUC=0.771, val_acc=0.709, val_AUC=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6610, -0.1437,  0.1702,  0.0614,  1.7301, -0.3758,  0.1454,  0.2059,\n",
      "        -0.5911,  0.3456, -0.7138, -0.3509, -0.3101,  0.0292, -0.0257,  0.0294,\n",
      "         0.4546], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 12/12 [00:01<00:00,  8.74it/s, loss=58.7, acc=0.702, AUC=0.769, val_acc=0.709, val_AUC=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6586, -0.1280,  0.1719,  0.0512,  1.7347, -0.3878,  0.1316,  0.2087,\n",
      "        -0.5819,  0.3494, -0.7117, -0.3499, -0.3097,  0.0176, -0.0305,  0.0313,\n",
      "         0.4617], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 12/12 [00:01<00:00,  8.75it/s, loss=58.3, acc=0.707, AUC=0.773, val_acc=0.712, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6518, -0.1195,  0.1730,  0.0492,  1.7249, -0.3844,  0.1331,  0.2278,\n",
      "        -0.5949,  0.3542, -0.7285, -0.3399, -0.3212,  0.0197, -0.0338,  0.0348,\n",
      "         0.4572], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 12/12 [00:01<00:00,  8.74it/s, loss=58.3, acc=0.705, AUC=0.773, val_acc=0.703, val_AUC=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6622, -0.1174,  0.1646,  0.0519,  1.7331, -0.3955,  0.1218,  0.2427,\n",
      "        -0.5917,  0.3555, -0.7188, -0.3402, -0.3144,  0.0078, -0.0187,  0.0296,\n",
      "         0.4519], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 12/12 [00:01<00:00,  8.74it/s, loss=58.4, acc=0.702, AUC=0.772, val_acc=0.709, val_AUC=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6717, -0.1118,  0.1659,  0.0492,  1.7325, -0.3806,  0.1387,  0.2372,\n",
      "        -0.6036,  0.3603, -0.7300, -0.3306, -0.3196,  0.0024, -0.0133,  0.0327,\n",
      "         0.4425], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 12/12 [00:01<00:00,  8.70it/s, loss=58.2, acc=0.706, AUC=0.774, val_acc=0.703, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6759, -0.1226,  0.1770,  0.0679,  1.7200, -0.3846,  0.1497,  0.2364,\n",
      "        -0.6073,  0.3605, -0.7320, -0.3334, -0.3186,  0.0081, -0.0121,  0.0276,\n",
      "         0.4395], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 12/12 [00:01<00:00,  8.68it/s, loss=58.3, acc=0.703, AUC=0.772, val_acc=0.702, val_AUC=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6827, -0.1370,  0.1835,  0.0643,  1.7411, -0.4019,  0.1522,  0.2247,\n",
      "        -0.5935,  0.3727, -0.7216, -0.3366, -0.3339,  0.0041, -0.0112,  0.0284,\n",
      "         0.4475], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 12/12 [00:01<00:00,  8.63it/s, loss=57.8, acc=0.709, AUC=0.777, val_acc=0.702, val_AUC=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6860, -0.1268,  0.1958,  0.0782,  1.7433, -0.4284,  0.1589,  0.2214,\n",
      "        -0.5892,  0.3658, -0.7289, -0.3488, -0.3319,  0.0127, -0.0098,  0.0292,\n",
      "         0.4445], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 12/12 [00:01<00:00,  8.64it/s, loss=58.1, acc=0.707, AUC=0.775, val_acc=0.714, val_AUC=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6727, -0.0953,  0.1988,  0.0842,  1.7402, -0.4476,  0.1541,  0.2206,\n",
      "        -0.5743,  0.3759, -0.7277, -0.3662, -0.3369, -0.0082, -0.0122,  0.0268,\n",
      "         0.4404], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 12/12 [00:01<00:00,  8.64it/s, loss=58, acc=0.71, AUC=0.776, val_acc=0.715, val_AUC=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6684, -0.0981,  0.2014,  0.0792,  1.7350, -0.4729,  0.1597,  0.2115,\n",
      "        -0.5558,  0.3824, -0.7202, -0.3739, -0.3367, -0.0191,  0.0144,  0.0270,\n",
      "         0.4343], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 12/12 [00:01<00:00,  8.55it/s, loss=57.9, acc=0.709, AUC=0.777, val_acc=0.708, val_AUC=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6760, -0.0946,  0.1898,  0.0900,  1.7346, -0.4908,  0.1670,  0.2082,\n",
      "        -0.5530,  0.3833, -0.7324, -0.3830, -0.3335, -0.0174,  0.0423,  0.0293,\n",
      "         0.4360], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 12/12 [00:01<00:00,  8.62it/s, loss=57.9, acc=0.708, AUC=0.776, val_acc=0.705, val_AUC=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6791, -0.0881,  0.1854,  0.1001,  1.7417, -0.4997,  0.1564,  0.2136,\n",
      "        -0.5383,  0.3812, -0.7256, -0.3906, -0.3368, -0.0167,  0.0417,  0.0226,\n",
      "         0.4322], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 12/12 [00:01<00:00,  8.58it/s, loss=57.7, acc=0.711, AUC=0.778, val_acc=0.706, val_AUC=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6693, -0.0809,  0.1826,  0.1066,  1.7348, -0.5048,  0.1798,  0.2114,\n",
      "        -0.5539,  0.3952, -0.7295, -0.3819, -0.3375, -0.0305,  0.0358,  0.0234,\n",
      "         0.4188], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 12/12 [00:01<00:00,  8.58it/s, loss=57.5, acc=0.709, AUC=0.78, val_acc=0.706, val_AUC=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6578, -0.0583,  0.1677,  0.0928,  1.7376, -0.5015,  0.1984,  0.2102,\n",
      "        -0.5514,  0.4058, -0.7415, -0.3832, -0.3438, -0.0428,  0.0281,  0.0297,\n",
      "         0.4100], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 12/12 [00:01<00:00,  8.50it/s, loss=57.6, acc=0.713, AUC=0.779, val_acc=0.705, val_AUC=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6502, -0.0420,  0.1798,  0.0770,  1.7414, -0.5101,  0.2038,  0.2209,\n",
      "        -0.5532,  0.4054, -0.7512, -0.3772, -0.3514, -0.0450,  0.0310,  0.0167,\n",
      "         0.4045], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 12/12 [00:01<00:00,  8.53it/s, loss=57.5, acc=0.713, AUC=0.78, val_acc=0.702, val_AUC=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6459, -0.0486,  0.1689,  0.0685,  1.7445, -0.5229,  0.1970,  0.2283,\n",
      "        -0.5409,  0.4051, -0.7482, -0.3787, -0.3463, -0.0491,  0.0467,  0.0211,\n",
      "         0.4004], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 12/12 [00:01<00:00,  8.50it/s, loss=57.6, acc=0.71, AUC=0.78, val_acc=0.714, val_AUC=0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6418, -0.0469,  0.1605,  0.0804,  1.7209, -0.5306,  0.1982,  0.2388,\n",
      "        -0.5326,  0.4157, -0.7477, -0.3855, -0.3498, -0.0578,  0.0476,  0.0196,\n",
      "         0.4110], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 12/12 [00:01<00:00,  8.56it/s, loss=57.4, acc=0.714, AUC=0.781, val_acc=0.706, val_AUC=0.774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6348, -0.0523,  0.1668,  0.0747,  1.7215, -0.5344,  0.1936,  0.2404,\n",
      "        -0.5243,  0.4179, -0.7414, -0.3903, -0.3503, -0.0687,  0.0655,  0.0123,\n",
      "         0.4040], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 12/12 [00:01<00:00,  8.54it/s, loss=57.2, acc=0.715, AUC=0.783, val_acc=0.713, val_AUC=0.775]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6227, -0.0263,  0.1657,  0.0753,  1.7270, -0.5373,  0.1898,  0.2421,\n",
      "        -0.5321,  0.4224, -0.7460, -0.4029, -0.3652, -0.0805,  0.0662,  0.0135,\n",
      "         0.4109], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 12/12 [00:01<00:00,  8.56it/s, loss=57.5, acc=0.71, AUC=0.78, val_acc=0.711, val_AUC=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6093, -0.0051,  0.1732,  0.0609,  1.7307, -0.5295,  0.1920,  0.2362,\n",
      "        -0.5367,  0.4172, -0.7378, -0.4135, -0.3681, -0.0925,  0.0556,  0.0148,\n",
      "         0.4119], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 12/12 [00:01<00:00,  8.55it/s, loss=57.4, acc=0.71, AUC=0.781, val_acc=0.716, val_AUC=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6012,  0.0095,  0.1718,  0.0575,  1.7432, -0.5316,  0.1804,  0.2310,\n",
      "        -0.5158,  0.4216, -0.7502, -0.4178, -0.3757, -0.0868,  0.0520,  0.0019,\n",
      "         0.4102], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 12/12 [00:01<00:00,  8.53it/s, loss=57.3, acc=0.713, AUC=0.782, val_acc=0.702, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6048,  0.0058,  0.1800,  0.0645,  1.7415, -0.5538,  0.1949,  0.2188,\n",
      "        -0.5055,  0.4264, -0.7456, -0.4221, -0.3793, -0.1050,  0.0673,  0.0069,\n",
      "         0.4100], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 12/12 [00:01<00:00,  8.50it/s, loss=57.1, acc=0.715, AUC=0.784, val_acc=0.706, val_AUC=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5929,  0.0328,  0.1885,  0.0566,  1.7428, -0.5668,  0.2132,  0.2168,\n",
      "        -0.5202,  0.4338, -0.7584, -0.4217, -0.3867, -0.1039,  0.0485,  0.0066,\n",
      "         0.4109], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 12/12 [00:01<00:00,  8.49it/s, loss=57.2, acc=0.71, AUC=0.783, val_acc=0.709, val_AUC=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5956,  0.0295,  0.1881,  0.0643,  1.7301, -0.5646,  0.2098,  0.2246,\n",
      "        -0.5162,  0.4382, -0.7699, -0.4161, -0.3883, -0.1045,  0.0408,  0.0065,\n",
      "         0.4233], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "test_acc: 0.6869301199913025\n",
      "test_auc: 0.7606430155210643\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seed_set = [9,90,900,9000,90000]\n",
    "overall_train(x, y, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155015230178833"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7051671743392944,\n",
    "     0.7082067131996155,\n",
    "     0.7051671743392944,\n",
    "     0.7264437675476074,\n",
    "     0.7325227856636047\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940417876933872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7808573540280858,\n",
    "     0.7863905325443787,\n",
    "     0.7797353553374963,\n",
    "     0.8075237670825907,\n",
    "     0.8157019294743846\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
