{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsou/.conda/envs/pyg/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import seed_everything\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import torch_geometric\n",
    "from tqdm import tqdm, trange\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cuda')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16644, 17]) torch.Size([16644])\n",
      "[2, 3, 6, 13, 10, 3, 1, 10, 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>juv_fel_count</th>\n",
       "      <th>juv_misd_count</th>\n",
       "      <th>juv_other_count</th>\n",
       "      <th>priors_count</th>\n",
       "      <th>days_b_screening_arrest</th>\n",
       "      <th>c_days_from_compas</th>\n",
       "      <th>end</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_cat</th>\n",
       "      <th>race</th>\n",
       "      <th>c_charge_degree</th>\n",
       "      <th>decile_score.1</th>\n",
       "      <th>score_text</th>\n",
       "      <th>v_type_of_assessment</th>\n",
       "      <th>v_decile_score</th>\n",
       "      <th>v_score_text</th>\n",
       "      <th>is_recid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.763142</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>0.360236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277735</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-1.493342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.069224</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.030074</td>\n",
       "      <td>-0.744908</td>\n",
       "      <td>0.051069</td>\n",
       "      <td>1.034535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.884913</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.030074</td>\n",
       "      <td>-0.190846</td>\n",
       "      <td>-0.118240</td>\n",
       "      <td>0.366177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.849881</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>7.344876</td>\n",
       "      <td>-0.584398</td>\n",
       "      <td>-0.350908</td>\n",
       "      <td>-0.069329</td>\n",
       "      <td>1.287026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16639</th>\n",
       "      <td>-1.110101</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>1.319701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16640</th>\n",
       "      <td>-0.329443</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>-0.245741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16641</th>\n",
       "      <td>-0.329443</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.769173</td>\n",
       "      <td>-0.067721</td>\n",
       "      <td>-0.155864</td>\n",
       "      <td>0.235476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16642</th>\n",
       "      <td>-0.936621</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.080033</td>\n",
       "      <td>-0.152102</td>\n",
       "      <td>-1.053711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16643</th>\n",
       "      <td>-0.936621</td>\n",
       "      <td>-0.17116</td>\n",
       "      <td>-0.195994</td>\n",
       "      <td>-0.249708</td>\n",
       "      <td>-0.399623</td>\n",
       "      <td>-0.080033</td>\n",
       "      <td>-0.152102</td>\n",
       "      <td>0.083982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16644 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  juv_fel_count  juv_misd_count  juv_other_count  priors_count  \\\n",
       "0     -0.763142       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "1      0.277735       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "2     -0.069224       -0.17116       -0.195994        -0.249708     -0.030074   \n",
       "3      0.884913       -0.17116       -0.195994        -0.249708     -0.030074   \n",
       "4     -0.849881       -0.17116       -0.195994         7.344876     -0.584398   \n",
       "...         ...            ...             ...              ...           ...   \n",
       "16639 -1.110101       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16640 -0.329443       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16641 -0.329443       -0.17116       -0.195994        -0.249708     -0.769173   \n",
       "16642 -0.936621       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "16643 -0.936621       -0.17116       -0.195994        -0.249708     -0.399623   \n",
       "\n",
       "       days_b_screening_arrest  c_days_from_compas       end  sex  age_cat  \\\n",
       "0                    -0.067721           -0.155864  0.360236  1.0      0.0   \n",
       "1                    -0.067721           -0.155864 -1.493342  0.0      0.0   \n",
       "2                    -0.744908            0.051069  1.034535  1.0      0.0   \n",
       "3                    -0.190846           -0.118240  0.366177  0.0      0.0   \n",
       "4                    -0.350908           -0.069329  1.287026  0.0      2.0   \n",
       "...                        ...                 ...       ...  ...      ...   \n",
       "16639                -0.067721           -0.155864  1.319701  1.0      2.0   \n",
       "16640                -0.067721           -0.155864 -0.245741  1.0      0.0   \n",
       "16641                -0.067721           -0.155864  0.235476  1.0      0.0   \n",
       "16642                -0.080033           -0.152102 -1.053711  0.0      2.0   \n",
       "16643                -0.080033           -0.152102  0.083982  0.0      2.0   \n",
       "\n",
       "       race  c_charge_degree  decile_score.1  score_text  \\\n",
       "0       0.0              3.0             3.0         1.0   \n",
       "1       2.0              2.0             4.0         2.0   \n",
       "2       2.0              6.0             5.0         2.0   \n",
       "3       2.0              2.0             3.0         1.0   \n",
       "4       2.0              7.0             3.0         1.0   \n",
       "...     ...              ...             ...         ...   \n",
       "16639   2.0              7.0             5.0         2.0   \n",
       "16640   0.0              7.0             1.0         1.0   \n",
       "16641   0.0              7.0             1.0         1.0   \n",
       "16642   3.0              3.0             3.0         1.0   \n",
       "16643   3.0              3.0             3.0         1.0   \n",
       "\n",
       "       v_type_of_assessment  v_decile_score  v_score_text  is_recid  \n",
       "0                       0.0             3.0           1.0         0  \n",
       "1                       0.0             1.0           1.0         0  \n",
       "2                       0.0             4.0           2.0         0  \n",
       "3                       0.0             1.0           1.0         0  \n",
       "4                       0.0             3.0           1.0         0  \n",
       "...                     ...             ...           ...       ...  \n",
       "16639                   0.0             6.0           2.0         1  \n",
       "16640                   0.0             1.0           1.0         1  \n",
       "16641                   0.0             1.0           1.0         1  \n",
       "16642                   0.0             3.0           1.0         1  \n",
       "16643                   0.0             3.0           1.0         1  \n",
       "\n",
       "[16644 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature from csv\n",
    "# RAW_data = pd.read_csv('data/adult.csv')\n",
    "# CAT = ['workclass','education','marital-status','occupation','relationship','race','gender','native-country']\n",
    "# NUM = ['age','fnlwgt','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "# LABEL = 'income'\n",
    "RAW_data = pd.read_csv('data/compass_old.csv')\n",
    "CAT=['sex','age_cat','race','c_charge_degree','decile_score.1','score_text','v_type_of_assessment','v_decile_score','v_score_text']\n",
    "NUM=['age','juv_fel_count','juv_misd_count','juv_other_count','priors_count','days_b_screening_arrest','c_days_from_compas','end']\n",
    "LABEL = 'is_recid'\n",
    "# convert categorical data to ordinal data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "data_pd = RAW_data.copy()\n",
    "data_pd[CAT] = enc.fit_transform(RAW_data[CAT])\n",
    "# data_pd = pd.get_dummies(RAW_data, columns=CAT, dtype=float)\n",
    "# label to category\n",
    "data_pd[LABEL] = data_pd[LABEL].astype('category').cat.codes\n",
    "\n",
    "# realign data to num + cat\n",
    "data_pd = data_pd[NUM + CAT + [LABEL]]\n",
    "\n",
    "# caculate unique value of each categorical feature\n",
    "cat_num = [len(data_pd[col].unique()) for col in CAT]\n",
    "\n",
    "# normalize numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_pd[NUM] = scaler.fit_transform(data_pd[NUM])\n",
    "\n",
    "# convert data to tensor\n",
    "x = torch.tensor(data_pd.drop(columns=[LABEL]).values, dtype=torch.float, device=DEVICE)  # [48842, 108]\n",
    "y = torch.tensor(data_pd[LABEL].values, dtype=torch.long, device=DEVICE) # [48842]\n",
    "print(x.shape, y.shape)\n",
    "print(cat_num)\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_improtance_extractor():\n",
    "    def __init__(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        pass\n",
    "    def update(self, new_feature_importance):\n",
    "        if self.iter == 0:\n",
    "            self.feature_importance = new_feature_importance\n",
    "        else:\n",
    "            self.feature_importance += new_feature_importance\n",
    "        self.iter += 1\n",
    "        return\n",
    "    \n",
    "    def get(self):\n",
    "        return (self.feature_importance / self.iter)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        return\n",
    "extractor = feature_improtance_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_graph(torch.nn.Module):\n",
    "    def __init__(self, NUM, CAT, LABEL, cat_num):\n",
    "        super(K_graph, self).__init__()\n",
    "        '''\n",
    "        num_cols: number of numerical columns\n",
    "        cat_cols: number of categorical columns\n",
    "        label_cols: number of label columns\n",
    "        cat_num: number of unique value of each categorical columns\n",
    "        '''\n",
    "        self.hidden_dim = 128\n",
    "        # order: num -> cat -> label\n",
    "        self.num_cols = len(NUM)\n",
    "        self.cat_cols = len(CAT)\n",
    "        self.label_cols = len(LABEL)\n",
    "        self.number_of_columns = self.num_cols + self.cat_cols \n",
    "        self.K = round(self.number_of_columns*0.5)\n",
    "        \n",
    "        # numerical feature\n",
    "        self.num_embeddings = torch.nn.ModuleList([torch.nn.Linear(1, self.hidden_dim) for i in range(self.num_cols)])\n",
    "        # categorical feature\n",
    "        self.cat_embeddings = torch.nn.ModuleList([torch.nn.Embedding(cat_num[i], self.hidden_dim) for i in range(self.cat_cols)])\n",
    "        \n",
    "        self.prediction = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim *( self.K + self.number_of_columns), self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Linear(self.hidden_dim, self.label_cols + 1)\n",
    "        )\n",
    "        \n",
    "        # feature importance learning\n",
    "        self.feature_importance_learners = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        ) \n",
    "        \n",
    "        # graph convolution layers\n",
    "        self.conv_GCN_input = torch_geometric.nn.GCNConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_GCN_input = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_1_input = torch_geometric.nn.GATConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        self.conv_GCN_2 = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        # self.transform = torch.nn.Linear(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, input_data, epoch = -1):\n",
    "        \n",
    "        # make feature embedding\n",
    "        num_data = input_data[:,:self.num_cols].unsqueeze(-1).unsqueeze(-1) \n",
    "        feature_embedding_num = torch.cat([self.num_embeddings[i](num_data[:,i]) for i in range(self.num_cols)], dim=1).reshape(len(input_data), -1) # [batch_size, num_cols * hidden_dim]\n",
    "        feature_embedding_num = torch.nn.ReLU()(feature_embedding_num)\n",
    "        feature_embedding_num = torch.layer_norm(feature_embedding_num, feature_embedding_num.shape)\n",
    "        # categorical feature\n",
    "        feature_embedding_cat = torch.cat([self.cat_embeddings[i](input_data[:,self.num_cols+i].long()) for i in range(self.cat_cols)], dim=1) # [batch_size, cat_cols * hidden_dim]\n",
    "        feature_embedding_cat = torch.layer_norm(feature_embedding_cat, feature_embedding_cat.shape)\n",
    "        # concat\n",
    "        feature_embedding = torch.cat((feature_embedding_num, feature_embedding_cat), dim=1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        # feature_embedding = feature_embedding.reshape((len(input_data), self.number_of_columns, -1)) # [batch_size, (num_cols + cat_cols), hidden_dim]\n",
    "        \n",
    "        # feature importance learning\n",
    "        feature_importance = torch.cat([self.feature_importance_learners(feature_embedding[:,i*self.hidden_dim:(i+1)*self.hidden_dim]) for i in range(self.number_of_columns)], dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance)\n",
    "        feature_importance = torch.layer_norm(feature_importance, feature_importance.shape)\n",
    "        # feature_importance = torch.softmax(feature_importance, dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance.shape)\n",
    "        # print(feature_importance.sum(dim=1))\n",
    "        # print(feature_importance)\n",
    "        \n",
    "        # weighted feature embedding \n",
    "        feature_embedding = feature_embedding.reshape((len(input_data),self.number_of_columns, -1)) * feature_importance.unsqueeze(-1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        feature_embedding = feature_embedding.reshape((len(input_data), -1)) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        \n",
    "        # top K feature importance\n",
    "        K = self.K\n",
    "        value, indices = torch.topk(feature_importance, K) # (value: [batch_size, k], indices: [batch_size, k])\n",
    "        mask = torch.zeros_like(feature_importance, device=DEVICE)\n",
    "        mask.scatter_(1, indices, 1)\n",
    "        # importance_topK = torch.where(mask > 0, feature_importance, torch.zeros(feature_importance.shape,device=DEVICE)) # [batch_size, cols]\n",
    "        importance_topK = torch.where(mask > 0, feature_importance, torch.empty(feature_importance.shape,device=DEVICE).fill_(-1e9)) # [batch_size, cols]\n",
    "        importance_topK = torch.softmax(importance_topK, dim=1) # [batch_size, cols]\n",
    "        # importance_topK = torch.stack([importance_topK.clone() for _ in range(self.number_of_columns)], dim=0) # [cols, batch_size, cols]\n",
    "        \n",
    "        extractor.update(feature_importance.sum(dim=0)/len(input_data))\n",
    "        del feature_embedding_num, feature_embedding_cat, num_data\n",
    "        del mask, feature_importance, value, indices\n",
    "        \n",
    "        \n",
    "        processed_data = []\n",
    "        processed_indices = []\n",
    "        for target_col in range(self.number_of_columns):\n",
    "            importance_topK_current = importance_topK.clone()# [batch_size, cols] \n",
    "            indices = importance_topK_current.T[target_col].nonzero().T[0] # selected samples' indices  \n",
    "            \n",
    "            if indices.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            importance_topK_current = importance_topK_current[importance_topK_current.T[target_col]>0]# [????, cols]\n",
    "            \n",
    "            # for target column, set its importance to 0. so that it will not be fully connected graph\n",
    "            # copy target column\n",
    "            tmp = torch.clone(importance_topK_current[:,target_col]) # [????], save for future weighted sum\n",
    "            importance_topK_current[:,target_col] = 0 # [????, cols]\n",
    "            # multiply to get weighted adj\n",
    "            weighted_adj = torch.matmul(importance_topK_current, importance_topK_current.T) # [batch_size, cols] * [cols, batch_size] = [batch_size, batch_size]\n",
    "            # prune the diagonal\n",
    "            weighted_adj = weighted_adj - torch.diag(weighted_adj.diagonal())\n",
    "\n",
    "            # construct graph\n",
    "            edge_index = weighted_adj.nonzero().T  # [2, num_edges]\n",
    "            edge_wight = weighted_adj[edge_index[0], edge_index[1]] # [num_edges]\n",
    "            edge_wight = torch.softmax(edge_wight, dim=0)\n",
    "\n",
    "            \n",
    "            if False:\n",
    "                print('in graph', target_col, 'nodes:', len(indices), 'edges:', len(edge_wight),'ratio', len(edge_wight)/(len(indices)**2+0.000001))\n",
    "            \n",
    "            # print(edge_wight)\n",
    "            # importance_topK_current[:,target_col] = tmp # [????, cols]\n",
    "            \n",
    "            features = (feature_embedding[indices]) # [????, cols*hidden_dim]\n",
    "            # features = (feature_embedding.reshape(len(input_data),self.number_of_columns,-1)[indices][:,target_col,:]) # [????, hidden_dim]\n",
    "            # print(features.shape)\n",
    "\n",
    "            # construct graph \n",
    "            data = Data(x=features, edge_index=edge_index, edge_weight=edge_wight, indices=indices) \n",
    "            \n",
    "            del features, edge_index, edge_wight, weighted_adj, importance_topK_current, tmp\n",
    "            \n",
    "            # apply GCN\n",
    "            x = self.conv_GCN_input(data.x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            # x = self.conv_1_input(data.x, data.edge_index)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape) # [???, hidden_dim]\n",
    "            x = torch.nn.Dropout(p=0.5)(x)\n",
    "            x = self.conv_GCN_2(x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape)\n",
    "\n",
    "            processed_data.append(x)\n",
    "            processed_indices.append(indices)\n",
    "        \n",
    "        processed_data = torch.cat(processed_data, dim=0) \n",
    "        processed_indices = torch.cat(processed_indices, dim=0)\n",
    "        # print(processed_indices)\n",
    "        # print(processed_indices.argsort())\n",
    "        # print(processed_indices[processed_indices.argsort()])\n",
    "        processed_data = processed_data[processed_indices.argsort()] # ???????\n",
    "        processed_data = torch.split(processed_data, self.K) # ?????????\n",
    "        processed_data = torch.stack(list(processed_data), dim=0) # ???????????\n",
    "        # processed_data = torch.sum(list(processed_data), dim=0) # ???????????\n",
    "\n",
    "        # cat residual\n",
    "        processed_data = torch.cat((processed_data, feature_embedding.reshape((len(input_data),self.number_of_columns,-1))), dim=1) # [batch_size, K+cols , hidden_dim]\n",
    "        \n",
    "        # make prediction\n",
    "        prediction = self.prediction(processed_data.reshape(processed_data.shape[0],-1))\n",
    "        # prediction = self.prediction(feature_embedding)\n",
    "        \n",
    "        \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0636],\n",
      "        [0.0636, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0364, 0.0268],\n",
      "        [0.0364, 0.0000, 0.0643],\n",
      "        [0.0268, 0.0643, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0533, 0.0912, 0.0317, 0.0592],\n",
      "        [0.0533, 0.0000, 0.0367, 0.0309, 0.0895],\n",
      "        [0.0912, 0.0367, 0.0000, 0.0864, 0.0430],\n",
      "        [0.0317, 0.0309, 0.0864, 0.0000, 0.0289],\n",
      "        [0.0592, 0.0895, 0.0430, 0.0289, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0363, 0.0942],\n",
      "        [0.0363, 0.0000, 0.0860],\n",
      "        [0.0942, 0.0860, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0268, 0.0362],\n",
      "        [0.0268, 0.0000, 0.0934],\n",
      "        [0.0362, 0.0934, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0987],\n",
      "        [0.0987, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0550, 0.1056, 0.0999],\n",
      "        [0.0550, 0.0000, 0.0281, 0.0865],\n",
      "        [0.1056, 0.0281, 0.0000, 0.0584],\n",
      "        [0.0999, 0.0865, 0.0584, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0571, 0.0597, 0.0932],\n",
      "        [0.0571, 0.0000, 0.0348, 0.0929],\n",
      "        [0.0597, 0.0348, 0.0000, 0.0608],\n",
      "        [0.0932, 0.0929, 0.0608, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0552, 0.0923],\n",
      "        [0.0552, 0.0000, 0.0533],\n",
      "        [0.0923, 0.0533, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0743, 0.0426, 0.0807],\n",
      "        [0.0743, 0.0000, 0.0735, 0.0358],\n",
      "        [0.0426, 0.0735, 0.0000, 0.0506],\n",
      "        [0.0807, 0.0358, 0.0506, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0641],\n",
      "        [0.0641, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0967],\n",
      "        [0.0967, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-----------------------------------------\n",
      "tensor([[0.0000, 0.1142, 0.0922, 0.1309],\n",
      "        [0.1142, 0.0000, 0.1240, 0.1448],\n",
      "        [0.0922, 0.1240, 0.0000, 0.0913],\n",
      "        [0.1309, 0.1448, 0.0913, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1034, 0.0666, 0.0738, 0.1194],\n",
      "        [0.1034, 0.0000, 0.0982, 0.0765, 0.1322],\n",
      "        [0.0666, 0.0982, 0.0000, 0.0543, 0.0631],\n",
      "        [0.0738, 0.0765, 0.0543, 0.0000, 0.0861],\n",
      "        [0.1194, 0.1322, 0.0631, 0.0861, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1385],\n",
      "        [0.1385, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0928],\n",
      "        [0.0928, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1135, 0.1324],\n",
      "        [0.1135, 0.0000, 0.1276],\n",
      "        [0.1324, 0.1276, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1126, 0.1179, 0.1202],\n",
      "        [0.1126, 0.0000, 0.1167, 0.1339],\n",
      "        [0.1179, 0.1167, 0.0000, 0.1240],\n",
      "        [0.1202, 0.1339, 0.1240, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1081, 0.0778, 0.1155, 0.1316],\n",
      "        [0.1081, 0.0000, 0.0794, 0.1035, 0.1358],\n",
      "        [0.0778, 0.0794, 0.0000, 0.1121, 0.0723],\n",
      "        [0.1155, 0.1035, 0.1121, 0.0000, 0.1267],\n",
      "        [0.1316, 0.1358, 0.0723, 0.1267, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1151],\n",
      "        [0.1151, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0484, 0.0730, 0.0794, 0.0603],\n",
      "        [0.0484, 0.0000, 0.0993, 0.0738, 0.0654],\n",
      "        [0.0730, 0.0993, 0.0000, 0.1284, 0.0649],\n",
      "        [0.0794, 0.0738, 0.1284, 0.0000, 0.0841],\n",
      "        [0.0603, 0.0654, 0.0649, 0.0841, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1119, 0.0972, 0.1180, 0.1288],\n",
      "        [0.1119, 0.0000, 0.1254, 0.1154, 0.1392],\n",
      "        [0.0972, 0.1254, 0.0000, 0.1443, 0.0930],\n",
      "        [0.1180, 0.1154, 0.1443, 0.0000, 0.1290],\n",
      "        [0.1288, 0.1392, 0.0930, 0.1290, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-----------------------------------------\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0969],\n",
      "        [0.0969, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0590, 0.1293, 0.1363, 0.1633],\n",
      "        [0.0590, 0.0000, 0.0695, 0.1008, 0.0799],\n",
      "        [0.1293, 0.0695, 0.0000, 0.1166, 0.1444],\n",
      "        [0.1363, 0.1008, 0.1166, 0.0000, 0.1573],\n",
      "        [0.1633, 0.0799, 0.1444, 0.1573, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0515, 0.1299, 0.1226, 0.1590],\n",
      "        [0.0515, 0.0000, 0.0678, 0.0695, 0.0696],\n",
      "        [0.1299, 0.0678, 0.0000, 0.1038, 0.1425],\n",
      "        [0.1226, 0.0695, 0.1038, 0.0000, 0.1404],\n",
      "        [0.1590, 0.0696, 0.1425, 0.1404, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1095],\n",
      "        [0.1095, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0805, 0.0771],\n",
      "        [0.0805, 0.0000, 0.1476],\n",
      "        [0.0771, 0.1476, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0623, 0.1360, 0.1619],\n",
      "        [0.0623, 0.0000, 0.0849, 0.0802],\n",
      "        [0.1360, 0.0849, 0.0000, 0.1478],\n",
      "        [0.1619, 0.0802, 0.1478, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1373, 0.1375, 0.1628],\n",
      "        [0.1373, 0.0000, 0.1303, 0.1515],\n",
      "        [0.1375, 0.1303, 0.0000, 0.1582],\n",
      "        [0.1628, 0.1515, 0.1582, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0296, 0.0533, 0.0331, 0.0292],\n",
      "        [0.0296, 0.0000, 0.0634, 0.0784, 0.0431],\n",
      "        [0.0533, 0.0634, 0.0000, 0.0526, 0.0521],\n",
      "        [0.0331, 0.0784, 0.0526, 0.0000, 0.0344],\n",
      "        [0.0292, 0.0431, 0.0521, 0.0344, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1318, 0.1604],\n",
      "        [0.1318, 0.0000, 0.1430],\n",
      "        [0.1604, 0.1430, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1278],\n",
      "        [0.1278, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-----------------------------------------\n",
      "tensor([[0.0000, 0.1081],\n",
      "        [0.1081, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0894],\n",
      "        [0.0894, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1101, 0.0706, 0.1807, 0.1602],\n",
      "        [0.1101, 0.0000, 0.0551, 0.1214, 0.0956],\n",
      "        [0.0706, 0.0551, 0.0000, 0.0622, 0.0516],\n",
      "        [0.1807, 0.1214, 0.0622, 0.0000, 0.1675],\n",
      "        [0.1602, 0.0956, 0.0516, 0.1675, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0255, 0.0397, 0.0787, 0.0822],\n",
      "        [0.0255, 0.0000, 0.0564, 0.0728, 0.0585],\n",
      "        [0.0397, 0.0564, 0.0000, 0.0739, 0.0613],\n",
      "        [0.0787, 0.0728, 0.0739, 0.0000, 0.1237],\n",
      "        [0.0822, 0.0585, 0.0613, 0.1237, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1552],\n",
      "        [0.1552, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1801],\n",
      "        [0.1801, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0825],\n",
      "        [0.0825, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0650, 0.1127],\n",
      "        [0.0650, 0.0000, 0.1009],\n",
      "        [0.1127, 0.1009, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0775, 0.1149, 0.0931],\n",
      "        [0.0775, 0.0000, 0.1023, 0.0838],\n",
      "        [0.1149, 0.1023, 0.0000, 0.1690],\n",
      "        [0.0931, 0.0838, 0.1690, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0931, 0.0761, 0.1129, 0.0910],\n",
      "        [0.0931, 0.0000, 0.0768, 0.0993, 0.0724],\n",
      "        [0.0761, 0.0768, 0.0000, 0.0839, 0.0636],\n",
      "        [0.1129, 0.0993, 0.0839, 0.0000, 0.0737],\n",
      "        [0.0910, 0.0724, 0.0636, 0.0737, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1078, 0.0767],\n",
      "        [0.1078, 0.0000, 0.1581],\n",
      "        [0.0767, 0.1581, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-----------------------------------------\n",
      "tensor([[0.0000, 0.0916, 0.0741],\n",
      "        [0.0916, 0.0000, 0.1010],\n",
      "        [0.0741, 0.1010, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1367, 0.1271, 0.0731, 0.0665],\n",
      "        [0.1367, 0.0000, 0.1439, 0.1002, 0.1072],\n",
      "        [0.1271, 0.1439, 0.0000, 0.0987, 0.1235],\n",
      "        [0.0731, 0.1002, 0.0987, 0.0000, 0.0848],\n",
      "        [0.0665, 0.1072, 0.1235, 0.0848, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1057, 0.0382, 0.0577, 0.0412],\n",
      "        [0.1057, 0.0000, 0.0849, 0.0813, 0.0871],\n",
      "        [0.0382, 0.0849, 0.0000, 0.0443, 0.0655],\n",
      "        [0.0577, 0.0813, 0.0443, 0.0000, 0.0774],\n",
      "        [0.0412, 0.0871, 0.0655, 0.0774, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1255],\n",
      "        [0.1255, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0929],\n",
      "        [0.0929, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1383, 0.1353],\n",
      "        [0.1383, 0.0000, 0.1438],\n",
      "        [0.1353, 0.1438, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1042],\n",
      "        [0.1042, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1420, 0.1027, 0.0956],\n",
      "        [0.1420, 0.0000, 0.1076, 0.0968],\n",
      "        [0.1027, 0.1076, 0.0000, 0.0772],\n",
      "        [0.0956, 0.0968, 0.0772, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.1298, 0.1328, 0.0702],\n",
      "        [0.1298, 0.0000, 0.1368, 0.0939],\n",
      "        [0.1328, 0.1368, 0.0000, 0.1241],\n",
      "        [0.0702, 0.0939, 0.1241, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0920],\n",
      "        [0.0920, 0.0000]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.0000, 0.0658, 0.1177, 0.0766, 0.0622],\n",
      "        [0.0658, 0.0000, 0.0809, 0.0363, 0.0567],\n",
      "        [0.1177, 0.0809, 0.0000, 0.0972, 0.1175],\n",
      "        [0.0766, 0.0363, 0.0972, 0.0000, 0.0890],\n",
      "        [0.0622, 0.0567, 0.1175, 0.0890, 0.0000]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor([[0.]], device='cuda:0', grad_fn=<SubBackward0>)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer.step()\n",
    "data_count = 5\n",
    "# random pick data\n",
    "indices = torch.randperm(len(x))[:data_count]\n",
    "train_data = x[indices]\n",
    "train_label = y[indices]\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = the_model(train_data[:data_count], epoch=200)\n",
    "    loss = torch.nn.functional.cross_entropy(output, train_label[:data_count])\n",
    "    loss.backward()\n",
    "    # print(((the_model.feature_importance_learners.grad).abs().max(dim=1)[0]))\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLP+FI.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "plot = torchviz.make_dot(loss, params=dict(the_model.named_parameters()))\n",
    "plot.render(\"MLP+FI\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, datas, batch_size, epoch):\n",
    "    train_data, train_label, validation_data, validation_label = datas\n",
    "    \n",
    "    # slice data into batch\n",
    "    train_data = torch.split(train_data, batch_size)\n",
    "    train_label = torch.split(train_label, batch_size)\n",
    "    validation_data = torch.split(validation_data, batch_size)\n",
    "    validation_label = torch.split(validation_label, batch_size)\n",
    "\n",
    "    # losses and metrics\n",
    "    batch_loss = 0\n",
    "    train_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    train_auc = BinaryAUROC().to(DEVICE)\n",
    "    valid_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    valid_auc = BinaryAUROC().to(DEVICE)\n",
    "    \n",
    "    # train the model\n",
    "    stepper = trange(len(train_data))\n",
    "    for i in stepper:\n",
    "        stepper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data[i], epoch=epoch)\n",
    "        loss = torch.nn.functional.cross_entropy(output, train_label[i]) * model.number_of_columns\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # metrics\n",
    "        preds = output.softmax(dim=1)\n",
    "        true = torch.nn.functional.one_hot(train_label[i], num_classes=2).to(DEVICE)\n",
    "        train_acc.update(torch.argmax(preds, 1),true.T[1])\n",
    "        train_auc.update(preds.T[0],true.T[0])\n",
    "        \n",
    "        # at the end of epoch, print result and validate the model\n",
    "        if i == len(train_data) - 1:\n",
    "            train_acc = train_acc.compute()\n",
    "            train_auc = train_auc.compute()\n",
    "            stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3)})\n",
    "            stepper.update()\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for i in range(len(validation_data)):\n",
    "                    output = model(validation_data[i], epoch=200)\n",
    "                    # loss = torch.nn.functional.cross_entropy(output, validation_label[i])\n",
    "                    preds = output.softmax(dim=1)\n",
    "                    true = torch.nn.functional.one_hot(validation_label[i], num_classes=2).to(DEVICE)\n",
    "                    valid_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "                    valid_auc.update(preds.T[0],true.T[0])\n",
    "                stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3), 'val_acc': round(valid_acc.compute().item(), 3), 'val_AUC': round(valid_auc.compute().item(), 3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_train(x, y, seed=0):\n",
    "    # hyperparameter\n",
    "    epoch = 50\n",
    "    batch_size = 1000\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # shuffle data\n",
    "    indices = torch.randperm(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    # slice data into train and test and validation\n",
    "    train_ratio = 0.7\n",
    "    validation_ratio = 0.1\n",
    "    train_data = x[:int(len(x)*train_ratio)]\n",
    "    train_label = y[:int(len(x)*train_ratio)]\n",
    "    validation_data = x[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    validation_label = y[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    test_data = x[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "    test_label = y[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "\n",
    "    # build model and optimizer\n",
    "    the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # train the model\n",
    "    datas = (train_data, train_label, validation_data, validation_label)\n",
    "    for i in range(epoch):\n",
    "        train_epoch(the_model, optimizer, datas, batch_size, epoch=i+1)\n",
    "        print(extractor.get())\n",
    "        extractor.reset()\n",
    "    \n",
    "    # test the model\n",
    "    with torch.no_grad():\n",
    "        test_data = torch.split(test_data, batch_size)\n",
    "        test_label = torch.split(test_label, batch_size)\n",
    "        for i in range(len(test_data)):\n",
    "            output = the_model(test_data[i], epoch=200)\n",
    "            preds = output.softmax(dim=1)\n",
    "            true = torch.nn.functional.one_hot(test_label[i], num_classes=2).to(DEVICE)\n",
    "            test_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "            test_auc = BinaryAUROC().to(DEVICE)\n",
    "            test_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "            test_auc.update(preds.T[0],true.T[0])\n",
    "\n",
    "        print('test_acc:', test_acc.compute().item())\n",
    "        print('test_auc:', test_auc.compute().item())\n",
    "        print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 12/12 [00:03<00:00,  3.63it/s, loss=74.9, acc=0.593, AUC=0.62, val_acc=0.658, val_AUC=0.712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0910, -0.2222, -0.3857,  0.0628,  0.3273, -0.0124,  0.0954, -0.8044,\n",
      "         0.1037,  0.4230,  0.2478,  0.3863, -0.0551,  0.1489,  0.0644,  0.1103,\n",
      "        -0.5810], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 12/12 [00:03<00:00,  3.63it/s, loss=64, acc=0.657, AUC=0.709, val_acc=0.669, val_AUC=0.728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1120, -0.4597, -0.3330,  0.1018,  0.8076, -0.2562,  0.2192, -1.0856,\n",
      "        -0.1338,  0.2776,  0.3291,  0.5850,  0.0904,  0.2498,  0.1983,  0.2154,\n",
      "        -0.9181], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=62.9, acc=0.665, AUC=0.723, val_acc=0.674, val_AUC=0.729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0410, -0.5782, -0.3178,  0.0781,  1.0028, -0.3138,  0.3415, -1.2122,\n",
      "        -0.1296,  0.2900,  0.3395,  0.5836,  0.0958,  0.2608,  0.2855,  0.2366,\n",
      "        -1.0036], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=62, acc=0.678, AUC=0.734, val_acc=0.687, val_AUC=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0269, -0.6693, -0.3060,  0.0470,  1.1691, -0.3219,  0.3044, -1.2246,\n",
      "        -0.1671,  0.3052,  0.3474,  0.5829,  0.1107,  0.2341,  0.3496,  0.2562,\n",
      "        -1.0447], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=62, acc=0.677, AUC=0.733, val_acc=0.694, val_AUC=0.75]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0256, -0.7456, -0.3209, -0.0139,  1.3084, -0.3479,  0.3099, -1.1991,\n",
      "        -0.1691,  0.2990,  0.3737,  0.6115,  0.1223,  0.2092,  0.3086,  0.2781,\n",
      "        -1.0499], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=61.1, acc=0.685, AUC=0.743, val_acc=0.684, val_AUC=0.751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0403, -0.8373, -0.2922, -0.0361,  1.4152, -0.3776,  0.3008, -1.2062,\n",
      "        -0.1747,  0.2754,  0.3812,  0.6357,  0.1461,  0.1878,  0.3119,  0.2670,\n",
      "        -1.0373], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=61.2, acc=0.682, AUC=0.742, val_acc=0.695, val_AUC=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0594, -0.8881, -0.2717, -0.0358,  1.4820, -0.3556,  0.3187, -1.2052,\n",
      "        -0.2270,  0.2935,  0.4004,  0.6106,  0.1477,  0.1977,  0.2643,  0.2796,\n",
      "        -1.0704], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.8, acc=0.685, AUC=0.745, val_acc=0.688, val_AUC=0.744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0500, -0.9038, -0.2143, -0.0355,  1.5406, -0.3559,  0.2758, -1.2127,\n",
      "        -0.2535,  0.2849,  0.3936,  0.6044,  0.1414,  0.1961,  0.2834,  0.2794,\n",
      "        -1.0738], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.7, acc=0.689, AUC=0.748, val_acc=0.686, val_AUC=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0653, -0.9258, -0.2092, -0.0664,  1.5947, -0.3933,  0.2644, -1.2144,\n",
      "        -0.2400,  0.3023,  0.3918,  0.5833,  0.1434,  0.2254,  0.2800,  0.2734,\n",
      "        -1.0750], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 12/12 [00:03<00:00,  3.57it/s, loss=60.6, acc=0.692, AUC=0.749, val_acc=0.695, val_AUC=0.755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0703, -0.9457, -0.2420, -0.0640,  1.6420, -0.4096,  0.2266, -1.1742,\n",
      "        -0.2415,  0.2821,  0.3765,  0.5656,  0.1579,  0.2573,  0.2861,  0.2847,\n",
      "        -1.0720], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.6, acc=0.691, AUC=0.749, val_acc=0.686, val_AUC=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0859, -0.9707, -0.2461, -0.0498,  1.6612, -0.4279,  0.2050, -1.1613,\n",
      "        -0.2445,  0.2863,  0.3642,  0.5465,  0.1615,  0.2774,  0.2799,  0.2897,\n",
      "        -1.0572], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.5, acc=0.688, AUC=0.75, val_acc=0.696, val_AUC=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0841, -0.9647, -0.2376, -0.0362,  1.6993, -0.4652,  0.1627, -1.1259,\n",
      "        -0.2453,  0.2967,  0.3683,  0.5098,  0.1664,  0.2963,  0.2703,  0.2926,\n",
      "        -1.0715], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.1, acc=0.694, AUC=0.754, val_acc=0.701, val_AUC=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0954, -0.9673, -0.2177, -0.0435,  1.7140, -0.4785,  0.1368, -1.1312,\n",
      "        -0.2647,  0.2910,  0.3712,  0.5119,  0.1623,  0.2969,  0.2818,  0.3044,\n",
      "        -1.0628], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.2, acc=0.693, AUC=0.752, val_acc=0.687, val_AUC=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0910, -0.9546, -0.2291, -0.0145,  1.7177, -0.4867,  0.1261, -1.1447,\n",
      "        -0.3062,  0.3100,  0.3782,  0.5077,  0.1453,  0.3038,  0.3030,  0.2990,\n",
      "        -1.0460], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s, loss=60.1, acc=0.692, AUC=0.754, val_acc=0.687, val_AUC=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1119, -0.9488, -0.2158, -0.0060,  1.7407, -0.4974,  0.1036, -1.1195,\n",
      "        -0.3312,  0.3095,  0.3652,  0.5024,  0.1530,  0.2977,  0.2754,  0.3039,\n",
      "        -1.0447], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.8, acc=0.694, AUC=0.758, val_acc=0.69, val_AUC=0.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1160, -0.9114, -0.1994, -0.0023,  1.7682, -0.5049,  0.0473, -1.1137,\n",
      "        -0.3339,  0.3046,  0.3546,  0.4878,  0.1422,  0.2923,  0.2756,  0.3108,\n",
      "        -1.0338], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.8, acc=0.697, AUC=0.757, val_acc=0.692, val_AUC=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1370, -0.8913, -0.1846, -0.0057,  1.7827, -0.5133,  0.0090, -1.1098,\n",
      "        -0.3689,  0.2959,  0.3480,  0.4895,  0.1426,  0.2981,  0.2904,  0.3020,\n",
      "        -1.0219], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.7, acc=0.694, AUC=0.759, val_acc=0.704, val_AUC=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1528, -0.9073, -0.1919, -0.0039,  1.7942, -0.4961, -0.0197, -1.1007,\n",
      "        -0.3884,  0.3007,  0.3434,  0.4970,  0.1451,  0.2839,  0.2962,  0.3065,\n",
      "        -1.0119], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.7, acc=0.696, AUC=0.758, val_acc=0.702, val_AUC=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1708, -0.9114, -0.1876,  0.0074,  1.7998, -0.5092, -0.0251, -1.1034,\n",
      "        -0.4283,  0.3134,  0.3605,  0.4725,  0.1393,  0.2952,  0.2972,  0.2986,\n",
      "        -0.9896], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=59.6, acc=0.699, AUC=0.76, val_acc=0.708, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1803, -0.8929, -0.1982, -0.0196,  1.8299, -0.5116, -0.0253, -1.0988,\n",
      "        -0.4232,  0.3219,  0.3527,  0.4641,  0.1392,  0.3030,  0.2691,  0.2950,\n",
      "        -0.9857], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=59.5, acc=0.698, AUC=0.761, val_acc=0.707, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1890, -0.9098, -0.1914, -0.0248,  1.8283, -0.5153, -0.0364, -1.0752,\n",
      "        -0.4097,  0.3277,  0.3576,  0.4622,  0.1312,  0.3049,  0.2586,  0.2905,\n",
      "        -0.9875], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.3, acc=0.698, AUC=0.763, val_acc=0.694, val_AUC=0.758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2028, -0.9038, -0.1751, -0.0219,  1.8351, -0.5239, -0.0564, -1.0581,\n",
      "        -0.4287,  0.3284,  0.3471,  0.4808,  0.1331,  0.3003,  0.2409,  0.2884,\n",
      "        -0.9888], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=59.3, acc=0.699, AUC=0.762, val_acc=0.703, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2007, -0.9061, -0.1706, -0.0248,  1.8404, -0.5264, -0.0687, -1.0558,\n",
      "        -0.4356,  0.3251,  0.3587,  0.4773,  0.1335,  0.2997,  0.2360,  0.2954,\n",
      "        -0.9789], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.3, acc=0.698, AUC=0.763, val_acc=0.71, val_AUC=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1912, -0.9273, -0.1588, -0.0104,  1.8425, -0.5031, -0.0596, -1.0579,\n",
      "        -0.4394,  0.3380,  0.3792,  0.4551,  0.1201,  0.3028,  0.2252,  0.2863,\n",
      "        -0.9839], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.2, acc=0.704, AUC=0.763, val_acc=0.709, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1922, -0.9120, -0.1560, -0.0131,  1.8444, -0.4860, -0.0975, -1.0676,\n",
      "        -0.4347,  0.3604,  0.3860,  0.4611,  0.1160,  0.3024,  0.2166,  0.2736,\n",
      "        -0.9858], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59, acc=0.696, AUC=0.765, val_acc=0.705, val_AUC=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2041, -0.9151, -0.1639, -0.0113,  1.8495, -0.4833, -0.1082, -1.0678,\n",
      "        -0.4299,  0.3609,  0.3865,  0.4592,  0.1083,  0.3141,  0.2145,  0.2673,\n",
      "        -0.9850], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 12/12 [00:03<00:00,  3.55it/s, loss=59.1, acc=0.699, AUC=0.765, val_acc=0.703, val_AUC=0.761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1967, -0.8917, -0.1539, -0.0191,  1.8491, -0.4954, -0.0956, -1.0813,\n",
      "        -0.4226,  0.3598,  0.3875,  0.4434,  0.1128,  0.3209,  0.2118,  0.2609,\n",
      "        -0.9833], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 12/12 [00:03<00:00,  3.59it/s, loss=59.1, acc=0.701, AUC=0.764, val_acc=0.703, val_AUC=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9830e-01, -8.6992e-01, -1.6056e-01, -9.4425e-04,  1.8576e+00,\n",
      "        -5.0440e-01, -1.0998e-01, -1.0759e+00, -4.2374e-01,  3.5881e-01,\n",
      "         3.8260e-01,  4.3097e-01,  1.0913e-01,  3.3727e-01,  2.0217e-01,\n",
      "         2.5190e-01, -9.8335e-01], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=59, acc=0.703, AUC=0.766, val_acc=0.701, val_AUC=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1995, -0.8756, -0.1487, -0.0024,  1.8477, -0.4912, -0.1208, -1.0809,\n",
      "        -0.4267,  0.3588,  0.4086,  0.4289,  0.1032,  0.3243,  0.2048,  0.2473,\n",
      "        -0.9769], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.9, acc=0.702, AUC=0.767, val_acc=0.7, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1849, -0.8710, -0.1534, -0.0181,  1.8499, -0.5050, -0.1362, -1.0635,\n",
      "        -0.4287,  0.3755,  0.4072,  0.4289,  0.1029,  0.3240,  0.2235,  0.2557,\n",
      "        -0.9766], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=59, acc=0.7, AUC=0.765, val_acc=0.706, val_AUC=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1742, -0.8785, -0.1494,  0.0019,  1.8399, -0.5128, -0.1384, -1.0574,\n",
      "        -0.4589,  0.3846,  0.4220,  0.4203,  0.1062,  0.3329,  0.2369,  0.2454,\n",
      "        -0.9689], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.7, acc=0.704, AUC=0.769, val_acc=0.706, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1792, -0.8762, -0.1497,  0.0235,  1.8280, -0.4978, -0.1357, -1.0511,\n",
      "        -0.4855,  0.3834,  0.4371,  0.4140,  0.0980,  0.3252,  0.2302,  0.2441,\n",
      "        -0.9666], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.4, acc=0.704, AUC=0.772, val_acc=0.705, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1964, -0.8819, -0.1597,  0.0154,  1.8485, -0.4899, -0.1551, -1.0476,\n",
      "        -0.4759,  0.3822,  0.4594,  0.4069,  0.0880,  0.3146,  0.2246,  0.2409,\n",
      "        -0.9666], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.5, acc=0.706, AUC=0.77, val_acc=0.712, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1975, -0.8806, -0.1460,  0.0179,  1.8319, -0.4917, -0.1680, -1.0367,\n",
      "        -0.4929,  0.3933,  0.4569,  0.4116,  0.0909,  0.3075,  0.2184,  0.2470,\n",
      "        -0.9570], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.6, acc=0.704, AUC=0.77, val_acc=0.704, val_AUC=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1783, -0.8611, -0.1384,  0.0207,  1.8338, -0.4796, -0.1821, -1.0509,\n",
      "        -0.4998,  0.3924,  0.4774,  0.4042,  0.0891,  0.3133,  0.2103,  0.2440,\n",
      "        -0.9516], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.4, acc=0.705, AUC=0.771, val_acc=0.707, val_AUC=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1845, -0.8471, -0.1357,  0.0192,  1.8270, -0.4695, -0.1893, -1.0605,\n",
      "        -0.5087,  0.3879,  0.4937,  0.3946,  0.0845,  0.3274,  0.2042,  0.2412,\n",
      "        -0.9535], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 12/12 [00:03<00:00,  3.60it/s, loss=58.6, acc=0.703, AUC=0.769, val_acc=0.706, val_AUC=0.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1872, -0.8480, -0.1444,  0.0124,  1.8251, -0.4691, -0.1902, -1.0668,\n",
      "        -0.5127,  0.3824,  0.4920,  0.4101,  0.0872,  0.3192,  0.2094,  0.2484,\n",
      "        -0.9422], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.4, acc=0.704, AUC=0.772, val_acc=0.701, val_AUC=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1912, -0.8342, -0.1450,  0.0197,  1.8098, -0.4592, -0.1635, -1.0736,\n",
      "        -0.5343,  0.3784,  0.5198,  0.4213,  0.0755,  0.3124,  0.1888,  0.2389,\n",
      "        -0.9458], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.2, acc=0.707, AUC=0.773, val_acc=0.705, val_AUC=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1702, -0.8145, -0.1462,  0.0276,  1.8015, -0.4730, -0.1586, -1.0672,\n",
      "        -0.5494,  0.3798,  0.5405,  0.4072,  0.0701,  0.3292,  0.1822,  0.2323,\n",
      "        -0.9317], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.3, acc=0.701, AUC=0.772, val_acc=0.712, val_AUC=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1734, -0.8260, -0.1594,  0.0191,  1.7950, -0.4636, -0.1745, -1.0507,\n",
      "        -0.5529,  0.3880,  0.5530,  0.4055,  0.0705,  0.3338,  0.1719,  0.2368,\n",
      "        -0.9199], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.1, acc=0.707, AUC=0.774, val_acc=0.709, val_AUC=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1721, -0.8296, -0.1576,  0.0145,  1.7858, -0.4667, -0.2203, -1.0374,\n",
      "        -0.5613,  0.3969,  0.5663,  0.4053,  0.0790,  0.3460,  0.1697,  0.2450,\n",
      "        -0.9078], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=58.1, acc=0.709, AUC=0.775, val_acc=0.709, val_AUC=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1783, -0.8222, -0.1554,  0.0227,  1.7639, -0.4675, -0.2313, -1.0704,\n",
      "        -0.5497,  0.3981,  0.5715,  0.4131,  0.0705,  0.3423,  0.1865,  0.2464,\n",
      "        -0.8967], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.9, acc=0.71, AUC=0.777, val_acc=0.703, val_AUC=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1891, -0.8202, -0.1553,  0.0281,  1.7696, -0.4556, -0.2357, -1.0769,\n",
      "        -0.5388,  0.3994,  0.5820,  0.4027,  0.0628,  0.3317,  0.1889,  0.2319,\n",
      "        -0.9036], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.7, acc=0.709, AUC=0.778, val_acc=0.71, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1931, -0.8174, -0.1624,  0.0249,  1.7683, -0.4489, -0.2583, -1.0713,\n",
      "        -0.5507,  0.4046,  0.5837,  0.4113,  0.0622,  0.3277,  0.1928,  0.2428,\n",
      "        -0.9024], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.7, acc=0.713, AUC=0.779, val_acc=0.692, val_AUC=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1898, -0.8123, -0.1564,  0.0204,  1.7676, -0.4457, -0.2621, -1.0737,\n",
      "        -0.5445,  0.4063,  0.6003,  0.4031,  0.0558,  0.3378,  0.1834,  0.2261,\n",
      "        -0.8959], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 12/12 [00:03<00:00,  3.62it/s, loss=57.8, acc=0.709, AUC=0.777, val_acc=0.714, val_AUC=0.773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1986, -0.8128, -0.1618,  0.0308,  1.7681, -0.4584, -0.2747, -1.0681,\n",
      "        -0.5308,  0.4019,  0.6133,  0.3939,  0.0482,  0.3261,  0.1848,  0.2262,\n",
      "        -0.8854], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.7, acc=0.711, AUC=0.779, val_acc=0.705, val_AUC=0.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1927, -0.8098, -0.1750,  0.0417,  1.7592, -0.4476, -0.2869, -1.0703,\n",
      "        -0.5441,  0.4097,  0.6208,  0.3881,  0.0483,  0.3221,  0.2009,  0.2292,\n",
      "        -0.8792], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.7, acc=0.709, AUC=0.779, val_acc=0.712, val_AUC=0.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1954, -0.8043, -0.1846,  0.0387,  1.7375, -0.4665, -0.2932, -1.0431,\n",
      "        -0.5464,  0.4019,  0.6375,  0.3966,  0.0518,  0.3247,  0.2073,  0.2274,\n",
      "        -0.8807], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 12/12 [00:03<00:00,  3.61it/s, loss=57.7, acc=0.709, AUC=0.779, val_acc=0.702, val_AUC=0.769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.2019, -0.8125, -0.1797,  0.0366,  1.7382, -0.4702, -0.3154, -1.0306,\n",
      "        -0.5427,  0.4064,  0.6408,  0.3956,  0.0442,  0.3377,  0.2059,  0.2267,\n",
      "        -0.8830], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 12/12 [00:03<00:00,  3.62it/s, loss=57.1, acc=0.713, AUC=0.784, val_acc=0.706, val_AUC=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1809, -0.7920, -0.1780,  0.0283,  1.7456, -0.4753, -0.3254, -1.0185,\n",
      "        -0.5421,  0.4120,  0.6570,  0.3937,  0.0384,  0.3390,  0.1879,  0.2247,\n",
      "        -0.8761], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "test_acc: 0.7051671743392944\n",
      "test_auc: 0.7808573540280858\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seed_set = [9,90,900,9000,90000]\n",
    "overall_train(x, y, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155015230178833"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7051671743392944,\n",
    "     0.7082067131996155,\n",
    "     0.7051671743392944,\n",
    "     0.7264437675476074,\n",
    "     0.7325227856636047\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7940417876933872"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.7808573540280858,\n",
    "     0.7863905325443787,\n",
    "     0.7797353553374963,\n",
    "     0.8075237670825907,\n",
    "     0.8157019294743846\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
