{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric import seed_everything\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import torch_geometric\n",
    "from tqdm import tqdm, trange\n",
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# DEVICE = torch.device('cuda')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48842, 14]) torch.Size([48842])\n",
      "[9, 16, 7, 15, 6, 5, 2, 42]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.995129</td>\n",
       "      <td>0.351675</td>\n",
       "      <td>-1.197259</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.046942</td>\n",
       "      <td>-0.945524</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>0.772930</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.776316</td>\n",
       "      <td>1.394723</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.390683</td>\n",
       "      <td>-0.277844</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>0.886874</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.505691</td>\n",
       "      <td>-0.815954</td>\n",
       "      <td>-0.030373</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.841104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>-0.849254</td>\n",
       "      <td>0.640492</td>\n",
       "      <td>0.747550</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.195490</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>0.098933</td>\n",
       "      <td>-0.334178</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>1.411808</td>\n",
       "      <td>-0.357510</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>-1.213941</td>\n",
       "      <td>0.111984</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>-0.144804</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-1.648120</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>0.974183</td>\n",
       "      <td>0.930494</td>\n",
       "      <td>-0.419335</td>\n",
       "      <td>1.871315</td>\n",
       "      <td>-0.217127</td>\n",
       "      <td>-0.034087</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
       "0     -0.995129  0.351675        -1.197259     -0.144804     -0.217127   \n",
       "1     -0.046942 -0.945524        -0.419335     -0.144804     -0.217127   \n",
       "2     -0.776316  1.394723         0.747550     -0.144804     -0.217127   \n",
       "3      0.390683 -0.277844        -0.030373      0.886874     -0.217127   \n",
       "4     -1.505691 -0.815954        -0.030373     -0.144804     -0.217127   \n",
       "...         ...       ...              ...           ...           ...   \n",
       "48837 -0.849254  0.640492         0.747550     -0.144804     -0.217127   \n",
       "48838  0.098933 -0.334178        -0.419335     -0.144804     -0.217127   \n",
       "48839  1.411808 -0.357510        -0.419335     -0.144804     -0.217127   \n",
       "48840 -1.213941  0.111984        -0.419335     -0.144804     -0.217127   \n",
       "48841  0.974183  0.930494        -0.419335      1.871315     -0.217127   \n",
       "\n",
       "       hours-per-week  workclass  education  marital-status  occupation  \\\n",
       "0           -0.034087        4.0        1.0             4.0         7.0   \n",
       "1            0.772930        4.0       11.0             2.0         5.0   \n",
       "2           -0.034087        2.0        7.0             2.0        11.0   \n",
       "3           -0.034087        4.0       15.0             2.0         7.0   \n",
       "4           -0.841104        0.0       15.0             4.0         0.0   \n",
       "...               ...        ...        ...             ...         ...   \n",
       "48837       -0.195490        4.0        7.0             2.0        13.0   \n",
       "48838       -0.034087        4.0       11.0             2.0         7.0   \n",
       "48839       -0.034087        4.0       11.0             6.0         1.0   \n",
       "48840       -1.648120        4.0       11.0             4.0         1.0   \n",
       "48841       -0.034087        5.0       11.0             2.0         4.0   \n",
       "\n",
       "       relationship  race  gender  native-country  income  \n",
       "0               3.0   2.0     1.0            39.0       0  \n",
       "1               0.0   4.0     1.0            39.0       0  \n",
       "2               0.0   4.0     1.0            39.0       1  \n",
       "3               0.0   2.0     1.0            39.0       1  \n",
       "4               3.0   4.0     0.0            39.0       0  \n",
       "...             ...   ...     ...             ...     ...  \n",
       "48837           5.0   4.0     0.0            39.0       0  \n",
       "48838           0.0   4.0     1.0            39.0       1  \n",
       "48839           4.0   4.0     0.0            39.0       0  \n",
       "48840           3.0   4.0     1.0            39.0       0  \n",
       "48841           5.0   4.0     0.0            39.0       1  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get feature from csv\n",
    "RAW_data = pd.read_csv('data/adult.csv')\n",
    "CAT = ['workclass','education','marital-status','occupation','relationship','race','gender','native-country']\n",
    "NUM = ['age','fnlwgt','educational-num','capital-gain','capital-loss','hours-per-week']\n",
    "LABEL = 'income'\n",
    "# RAW_data = pd.read_csv('data/compass_old.csv')\n",
    "# CAT=['sex','age_cat','race','c_charge_degree','decile_score.1','score_text','v_type_of_assessment','v_decile_score','v_score_text']\n",
    "# NUM=['age','juv_fel_count','juv_misd_count','juv_other_count','priors_count','days_b_screening_arrest','c_days_from_compas','end']\n",
    "# LABEL = 'is_recid'\n",
    "# convert categorical data to ordinal data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "data_pd = RAW_data.copy()\n",
    "data_pd[CAT] = enc.fit_transform(RAW_data[CAT])\n",
    "# data_pd = pd.get_dummies(RAW_data, columns=CAT, dtype=float)\n",
    "# label to category\n",
    "data_pd[LABEL] = data_pd[LABEL].astype('category').cat.codes\n",
    "\n",
    "# realign data to num + cat\n",
    "data_pd = data_pd[NUM + CAT + [LABEL]]\n",
    "\n",
    "# caculate unique value of each categorical feature\n",
    "cat_num = [len(data_pd[col].unique()) for col in CAT]\n",
    "\n",
    "# normalize numerical data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_pd[NUM] = scaler.fit_transform(data_pd[NUM])\n",
    "\n",
    "# convert data to tensor\n",
    "x = torch.tensor(data_pd.drop(columns=[LABEL]).values, dtype=torch.float, device=DEVICE)  # [48842, 108]\n",
    "y = torch.tensor(data_pd[LABEL].values, dtype=torch.long, device=DEVICE) # [48842]\n",
    "print(x.shape, y.shape)\n",
    "print(cat_num)\n",
    "data_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_improtance_extractor():\n",
    "    def __init__(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        pass\n",
    "    def update(self, new_feature_importance):\n",
    "        if self.iter == 0:\n",
    "            self.feature_importance = new_feature_importance\n",
    "        else:\n",
    "            self.feature_importance += new_feature_importance\n",
    "        self.iter += 1\n",
    "        return\n",
    "    \n",
    "    def get(self):\n",
    "        return (self.feature_importance / self.iter)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.feature_importance = []\n",
    "        self.iter = 0\n",
    "        return\n",
    "extractor = feature_improtance_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_graph(torch.nn.Module):\n",
    "    def __init__(self, NUM, CAT, LABEL, cat_num):\n",
    "        super(K_graph, self).__init__()\n",
    "        '''\n",
    "        num_cols: number of numerical columns\n",
    "        cat_cols: number of categorical columns\n",
    "        label_cols: number of label columns\n",
    "        cat_num: number of unique value of each categorical columns\n",
    "        '''\n",
    "        self.hidden_dim = 128\n",
    "        # order: num -> cat -> label\n",
    "        self.num_cols = len(NUM)\n",
    "        self.cat_cols = len(CAT)\n",
    "        self.label_cols = len(LABEL)\n",
    "        self.number_of_columns = self.num_cols + self.cat_cols \n",
    "        self.K = round(self.number_of_columns*0.3)\n",
    "        \n",
    "        # numerical feature\n",
    "        self.num_embeddings = torch.nn.ModuleList([torch.nn.Linear(1, self.hidden_dim) for i in range(self.num_cols)])\n",
    "        # categorical feature\n",
    "        self.cat_embeddings = torch.nn.ModuleList([torch.nn.Embedding(cat_num[i], self.hidden_dim) for i in range(self.cat_cols)])\n",
    "        \n",
    "        self.prediction = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim *( self.K + self.number_of_columns), self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Linear(self.hidden_dim, self.label_cols + 1)\n",
    "        )\n",
    "        \n",
    "        # feature importance learning\n",
    "        self.feature_importance_learners = torch.nn.ModuleList([torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.LayerNorm(self.hidden_dim),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(self.hidden_dim, 1),\n",
    "        ) for i in range(self.number_of_columns)])\n",
    "        \n",
    "        for i in range(self.number_of_columns):\n",
    "            torch.nn.init.constant_(self.feature_importance_learners[i][0].weight, 0)\n",
    "            torch.nn.init.constant_(self.feature_importance_learners[i][0].bias, 0)\n",
    "            torch.nn.init.constant_(self.feature_importance_learners[i][4].weight, 0)\n",
    "            torch.nn.init.constant_(self.feature_importance_learners[i][4].bias, 0)\n",
    "        \n",
    "        # graph convolution layers\n",
    "        # self.conv_GCN_input = torch_geometric.nn.GCNConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        self.conv_GCN_input = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        # self.conv_1_input = torch_geometric.nn.GATConv(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        self.conv_GCN_2 = torch_geometric.nn.GCNConv(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        # self.transform = torch.nn.Linear(self.number_of_columns*self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, input_data, epoch = -1):\n",
    "        \n",
    "        # make feature embedding\n",
    "        num_data = input_data[:,:self.num_cols].unsqueeze(-1).unsqueeze(-1) \n",
    "        feature_embedding_num = torch.cat([self.num_embeddings[i](num_data[:,i]) for i in range(self.num_cols)], dim=1).reshape(len(input_data), -1) # [batch_size, num_cols * hidden_dim]\n",
    "        feature_embedding_num = torch.nn.ReLU()(feature_embedding_num)\n",
    "        feature_embedding_num = torch.layer_norm(feature_embedding_num, feature_embedding_num.shape)\n",
    "        # categorical feature\n",
    "        feature_embedding_cat = torch.cat([self.cat_embeddings[i](input_data[:,self.num_cols+i].long()) for i in range(self.cat_cols)], dim=1) # [batch_size, cat_cols * hidden_dim]\n",
    "        feature_embedding_cat = torch.layer_norm(feature_embedding_cat, feature_embedding_cat.shape)\n",
    "        # concat\n",
    "        feature_embedding = torch.cat((feature_embedding_num, feature_embedding_cat), dim=1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        # feature_embedding = feature_embedding.reshape((len(input_data), self.number_of_columns, -1)) # [batch_size, (num_cols + cat_cols), hidden_dim]\n",
    "        \n",
    "        # feature importance learning\n",
    "        feature_importance = torch.cat([self.feature_importance_learners[i](feature_embedding[:,i*self.hidden_dim:(i+1)*self.hidden_dim]) for i in range(self.number_of_columns)], dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        feature_importance = torch.layer_norm(feature_importance, feature_importance.shape)\n",
    "        feature_importance = torch.softmax(feature_importance, dim=1) # [batch_size, num_cols + cat_cols, 1]\n",
    "        # print(feature_importance.shape)\n",
    "        # print(feature_importance.sum(dim=1))\n",
    "        # print(feature_importance)\n",
    "        \n",
    "        # weighted feature embedding \n",
    "        feature_embedding = feature_embedding.reshape((len(input_data),self.number_of_columns, -1)) * feature_importance.unsqueeze(-1) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        feature_embedding = feature_embedding.reshape((len(input_data), -1)) # [batch_size, (num_cols + cat_cols) * hidden_dim]\n",
    "        \n",
    "        # top K feature importance\n",
    "        K = self.K\n",
    "        value, indices = torch.topk(feature_importance, K) # (value: [batch_size, k], indices: [batch_size, k])\n",
    "        mask = torch.zeros_like(feature_importance, device=DEVICE)\n",
    "        mask.scatter_(1, indices, 1)\n",
    "        importance_topK = torch.where(mask > 0, feature_importance, torch.zeros(feature_importance.shape,device=DEVICE)) # [batch_size, cols]\n",
    "        # importance_topK = torch.stack([importance_topK.clone() for _ in range(self.number_of_columns)], dim=0) # [cols, batch_size, cols]\n",
    "        \n",
    "        extractor.update(feature_importance.sum(dim=0))\n",
    "        del feature_embedding_num, feature_embedding_cat, num_data\n",
    "        del mask, feature_importance, value, indices\n",
    "        \n",
    "        \n",
    "        processed_data = []\n",
    "        processed_indices = []\n",
    "        for target_col in range(self.number_of_columns):\n",
    "            importance_topK_current = importance_topK.clone()# [batch_size, cols] \n",
    "            indices = importance_topK_current.T[target_col].nonzero().T[0] # selected samples' indices  \n",
    "            \n",
    "            if indices.shape[0] == 0:\n",
    "                continue\n",
    "            \n",
    "            importance_topK_current = importance_topK_current[importance_topK_current.T[target_col]>0]# [????, cols]\n",
    "            \n",
    "            # for target column, set its importance to 0. so that it will not be fully connected graph\n",
    "            # copy target column\n",
    "            tmp = torch.clone(importance_topK_current[:,target_col]) # [????], save for future weighted sum\n",
    "            importance_topK_current[:,target_col] = 0 # [????, cols]\n",
    "            # multiply to get weighted adj\n",
    "            weighted_adj = torch.matmul(importance_topK_current, importance_topK_current.T) # [batch_size, cols] * [cols, batch_size] = [batch_size, batch_size]\n",
    "            # prune the diagonal\n",
    "            weighted_adj = weighted_adj - torch.diag(weighted_adj.diagonal())\n",
    "\n",
    "            # construct graph\n",
    "            edge_index = weighted_adj.nonzero().T  # [2, num_edges]\n",
    "            edge_wight = weighted_adj[edge_index[0], edge_index[1]] # [num_edges]\n",
    "            edge_wight = torch.softmax(edge_wight, dim=0)\n",
    "\n",
    "            \n",
    "            if False:\n",
    "                print('in graph', target_col, 'nodes:', len(indices), 'edges:', len(edge_wight),'ratio', len(edge_wight)/(len(indices)**2+0.000001))\n",
    "            \n",
    "            # print(edge_wight)\n",
    "            # importance_topK_current[:,target_col] = tmp # [????, cols]\n",
    "            \n",
    "            # features = (feature_embedding[indices]) # [????, cols*hidden_dim]\n",
    "            features = (feature_embedding.reshape(len(input_data),self.number_of_columns,-1)[indices][:,target_col,:]) # [????, hidden_dim]\n",
    "            # print(features.shape)\n",
    "\n",
    "            # construct graph \n",
    "            data = Data(x=features, edge_index=edge_index, edge_weight=edge_wight, indices=indices) \n",
    "            \n",
    "            del features, edge_index, edge_wight, weighted_adj, importance_topK_current, tmp\n",
    "            \n",
    "            # apply GCN\n",
    "            x = self.conv_GCN_input(data.x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            # x = self.conv_1_input(data.x, data.edge_index)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape) # [???, hidden_dim]\n",
    "            x = torch.nn.Dropout(p=0.5)(x)\n",
    "            x = self.conv_GCN_2(x, data.edge_index, data.edge_weight)  # [???, hidden_dim]\n",
    "            x = torch.relu(x)\n",
    "            x = torch.layer_norm(x, x.shape)\n",
    "\n",
    "            processed_data.append(x)\n",
    "            processed_indices.append(indices)\n",
    "        \n",
    "        processed_data = torch.cat(processed_data, dim=0) \n",
    "        processed_indices = torch.cat(processed_indices, dim=0)\n",
    "        # print(processed_indices)\n",
    "        # print(processed_indices.argsort())\n",
    "        # print(processed_indices[processed_indices.argsort()])\n",
    "        processed_data = processed_data[processed_indices.argsort()] # [batch_size, hidden_dim]\n",
    "        processed_data = torch.split(processed_data, self.K) # (batch_size, K, hidden_dim)\n",
    "        processed_data = torch.stack(list(processed_data), dim=0) # [batch_size, K, hidden_dim]\n",
    "\n",
    "        # cat residual\n",
    "        processed_data = torch.cat((processed_data, feature_embedding.reshape((len(input_data),self.number_of_columns,-1))), dim=1) # [batch_size, K+cols , hidden_dim]\n",
    "        \n",
    "        # make prediction\n",
    "        prediction = self.prediction(processed_data.reshape(processed_data.shape[0],-1))\n",
    "        # prediction = self.prediction(feature_embedding)\n",
    "        \n",
    "        \n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "\n",
    "# optimizer.step()\n",
    "data_count = 5\n",
    "# random pick data\n",
    "indices = torch.randperm(len(x))[:data_count]\n",
    "train_data = x[indices]\n",
    "train_label = y[indices]\n",
    "\n",
    "for i in range(2):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    output = the_model(train_data[:data_count], epoch=200)\n",
    "    loss = torch.nn.functional.cross_entropy(output, train_label[:data_count])\n",
    "    loss.backward()\n",
    "    # print(((the_model.feature_importance_learners.grad).abs().max(dim=1)[0]))\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLP+FI.png'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "plot = torchviz.make_dot(loss, params=dict(the_model.named_parameters()))\n",
    "plot.render(\"MLP+FI\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(model, optimizer, datas, batch_size, epoch):\n",
    "    train_data, train_label, validation_data, validation_label = datas\n",
    "    \n",
    "    # slice data into batch\n",
    "    train_data = torch.split(train_data, batch_size)\n",
    "    train_label = torch.split(train_label, batch_size)\n",
    "    validation_data = torch.split(validation_data, batch_size)\n",
    "    validation_label = torch.split(validation_label, batch_size)\n",
    "\n",
    "    # losses and metrics\n",
    "    batch_loss = 0\n",
    "    train_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    train_auc = BinaryAUROC().to(DEVICE)\n",
    "    valid_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "    valid_auc = BinaryAUROC().to(DEVICE)\n",
    "    \n",
    "    # train the model\n",
    "    stepper = trange(len(train_data))\n",
    "    for i in stepper:\n",
    "        stepper.set_description(f'Epoch {epoch}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(train_data[i], epoch=epoch)\n",
    "        loss = torch.nn.functional.cross_entropy(output, train_label[i]) * model.number_of_columns\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        # metrics\n",
    "        preds = output.softmax(dim=1)\n",
    "        true = torch.nn.functional.one_hot(train_label[i], num_classes=2).to(DEVICE)\n",
    "        train_acc.update(torch.argmax(preds, 1),true.T[1])\n",
    "        train_auc.update(preds.T[0],true.T[0])\n",
    "        \n",
    "        # at the end of epoch, print result and validate the model\n",
    "        if i == len(train_data) - 1:\n",
    "            train_acc = train_acc.compute()\n",
    "            train_auc = train_auc.compute()\n",
    "            stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3)})\n",
    "            stepper.update()\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                for i in range(len(validation_data)):\n",
    "                    output = model(validation_data[i], epoch=200)\n",
    "                    # loss = torch.nn.functional.cross_entropy(output, validation_label[i])\n",
    "                    preds = output.softmax(dim=1)\n",
    "                    true = torch.nn.functional.one_hot(validation_label[i], num_classes=2).to(DEVICE)\n",
    "                    valid_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "                    valid_auc.update(preds.T[0],true.T[0])\n",
    "                stepper.set_postfix({'loss': round(batch_loss/(i+1), 3), 'acc': round(train_acc.item(), 3), 'AUC': round(train_auc.item(), 3), 'val_acc': round(valid_acc.compute().item(), 3), 'val_AUC': round(valid_auc.compute().item(), 3)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_train(x, y, seed=0):\n",
    "    # hyperparameter\n",
    "    epoch = 50\n",
    "    batch_size = 1000\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    # shuffle data\n",
    "    indices = torch.randperm(len(x))\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "    # slice data into train and test and validation\n",
    "    train_ratio = 0.7\n",
    "    validation_ratio = 0.1\n",
    "    train_data = x[:int(len(x)*train_ratio)]\n",
    "    train_label = y[:int(len(x)*train_ratio)]\n",
    "    validation_data = x[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    validation_label = y[int(len(x)*train_ratio):int(len(x)*(train_ratio+validation_ratio))]\n",
    "    test_data = x[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "    test_label = y[int(len(x)*(train_ratio+validation_ratio)):]\n",
    "\n",
    "    # build model and optimizer\n",
    "    the_model = K_graph(NUM, CAT, [LABEL], cat_num).to(DEVICE)\n",
    "    optimizer = torch.optim.SGD(the_model.parameters(), lr=0.001)\n",
    "    \n",
    "    # train the model\n",
    "    datas = (train_data, train_label, validation_data, validation_label)\n",
    "    for i in range(epoch):\n",
    "        train_epoch(the_model, optimizer, datas, batch_size, epoch=i+1)\n",
    "        print(extractor.get())\n",
    "        extractor.reset()\n",
    "    \n",
    "    # test the model\n",
    "    with torch.no_grad():\n",
    "        test_data = torch.split(test_data, batch_size)\n",
    "        test_label = torch.split(test_label, batch_size)\n",
    "        for i in range(len(test_data)):\n",
    "            output = the_model(test_data[i], epoch=200)\n",
    "            preds = output.softmax(dim=1)\n",
    "            true = torch.nn.functional.one_hot(test_label[i], num_classes=2).to(DEVICE)\n",
    "            test_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "            test_auc = BinaryAUROC().to(DEVICE)\n",
    "            test_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "            test_auc.update(preds.T[0],true.T[0])\n",
    "        # output = the_model(test_data, epoch=200)\n",
    "        # preds = output.softmax(dim=1)\n",
    "        # true = torch.nn.functional.one_hot(test_label, num_classes=2).to(DEVICE)\n",
    "        # test_acc = MulticlassAccuracy(num_classes=2).to(DEVICE)\n",
    "        # test_auc = BinaryAUROC().to(DEVICE)\n",
    "        # test_acc.update(torch.argmax(preds,1),true.T[1])\n",
    "        # test_auc.update(preds.T[0],true.T[0])\n",
    "        print('test_acc:', test_acc.compute().item())\n",
    "        print('test_auc:', test_auc.compute().item())\n",
    "        print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 10.32it/s, loss=44.3, acc=0.782, AUC=0.796, val_acc=0.806, val_AUC=0.844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 42.2897,  18.1787,  77.1797,  32.8793,  31.9462,  57.2528,  10.9467,\n",
      "         93.0086,  12.9357,  25.0136, 341.2386,  31.2167,  12.8721, 143.5891],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.58it/s, loss=39.4, acc=0.807, AUC=0.843, val_acc=0.804, val_AUC=0.846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 47.1663,  15.9831,  57.2612,  44.8532,  31.1761,  54.6521,   9.4843,\n",
      "         64.7513,  11.2442,  24.1347, 491.0917,  26.4991,  11.4132,  87.1145],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.50it/s, loss=38.7, acc=0.809, AUC=0.851, val_acc=0.817, val_AUC=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 56.0153,  15.3865,  60.5186,  70.7325,  34.2682,  61.2829,   9.5026,\n",
      "         57.0261,  11.0113,  25.8518, 478.8222,  24.2109,  11.3657,  60.8302],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=35.7, acc=0.827, AUC=0.874, val_acc=0.828, val_AUC=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 61.5871,  15.0903,  70.2212,  84.3282,  42.0825,  62.6273,   9.7797,\n",
      "         53.4818,  11.0896,  27.8584, 460.4090,  22.0674,  11.6088,  44.5936],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=34.7, acc=0.831, AUC=0.882, val_acc=0.814, val_AUC=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 78.9007,  15.3603,  80.7961, 103.5640,  65.9426,  78.3700,  10.1101,\n",
      "         53.3396,  11.4134,  32.7714, 373.6617,  21.4244,  11.9994,  39.1711],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=34.6, acc=0.834, AUC=0.882, val_acc=0.828, val_AUC=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 95.4135,  15.4862,  99.4980, 105.0547,  94.1847,  95.3722,  10.5689,\n",
      "         54.5104,  11.7806,  39.2054, 288.1467,  20.5135,  12.4147,  34.6754],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.44it/s, loss=34.1, acc=0.837, AUC=0.886, val_acc=0.821, val_AUC=0.877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([108.4009,  15.4861, 112.1850, 110.9667, 101.5084, 108.3048,  11.0811,\n",
      "         50.1043,  12.1124,  46.1670, 237.9611,  19.4743,  12.8702,  30.2027],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=33.4, acc=0.841, AUC=0.891, val_acc=0.84, val_AUC=0.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([113.8712,  15.3653, 121.2535, 116.5253, 105.4614, 115.6817,  11.4700,\n",
      "         46.3958,  12.3534,  57.7001, 201.5929,  18.6614,  13.2393,  27.2535],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.27it/s, loss=33.3, acc=0.842, AUC=0.892, val_acc=0.839, val_AUC=0.895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([116.6449,  15.3059, 121.5796, 119.9386, 102.5881, 117.8679,  11.8315,\n",
      "         43.1112,  12.5644,  78.7205, 179.9715,  18.0004,  13.5100,  25.1904],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=33.3, acc=0.841, AUC=0.892, val_acc=0.838, val_AUC=0.889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([112.0036,  15.3239, 119.3335, 120.9747,  97.8789, 111.7089,  12.1749,\n",
      "         40.5554,  12.7681, 108.0073, 171.0992,  17.5314,  13.8093,  23.6558],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.44it/s, loss=33, acc=0.843, AUC=0.894, val_acc=0.83, val_AUC=0.878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([116.6278,  15.3703, 123.2320, 123.6463,  91.1898, 120.2754,  12.5793,\n",
      "         38.2757,  12.9571, 119.3560, 149.5549,  17.0686,  14.1844,  22.5074],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=33, acc=0.843, AUC=0.894, val_acc=0.837, val_AUC=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([119.8806,  15.4619, 126.0020, 131.1959,  87.8840, 122.4543,  12.9499,\n",
      "         35.9116,  13.1787, 121.6958, 137.5244,  16.7040,  14.5616,  21.4204],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=32.4, acc=0.845, AUC=0.898, val_acc=0.84, val_AUC=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([121.4320,  15.4851, 126.6845, 128.3494,  87.7371, 120.7986,  13.2987,\n",
      "         33.9579,  13.3579, 123.4259, 140.3698,  16.4111,  14.9446,  20.5724],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=32.4, acc=0.847, AUC=0.898, val_acc=0.831, val_AUC=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([123.1869,  15.5543, 128.1312, 131.3935,  85.3850, 119.9752,  13.5875,\n",
      "         32.5533,  13.4985, 124.4668, 137.7819,  16.1911,  15.3066,  19.8132],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.40it/s, loss=32, acc=0.848, AUC=0.901, val_acc=0.834, val_AUC=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([123.2452,  15.6330, 129.2696, 133.2498,  83.2969, 120.3440,  13.8463,\n",
      "         31.5591,  13.6138, 123.8935, 138.0601,  15.9802,  15.5879,  19.2457],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.41it/s, loss=32.2, acc=0.846, AUC=0.9, val_acc=0.843, val_AUC=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([123.1581,  15.6963, 129.6574, 131.5189,  80.2894, 124.1972,  14.1113,\n",
      "         30.6690,  13.7228, 127.5257, 135.8681,  15.8111,  15.8232,  18.7765],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.9, acc=0.849, AUC=0.902, val_acc=0.835, val_AUC=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([125.4971,  15.7427, 129.4506, 136.3217,  76.7039, 121.5296,  14.3775,\n",
      "         29.6748,  13.8198, 126.8204, 136.7292,  15.6289,  16.1499,  18.3788],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31.8, acc=0.85, AUC=0.902, val_acc=0.834, val_AUC=0.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([127.6275,  15.8290, 128.8994, 133.2658,  76.1116, 117.6286,  14.6168,\n",
      "         28.7453,  13.8825, 127.3408, 142.9477,  15.4803,  16.4646,  17.9852],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31.6, acc=0.85, AUC=0.903, val_acc=0.843, val_AUC=0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([126.6557,  15.9168, 127.8689, 135.2773,  73.9018, 120.6604,  14.8200,\n",
      "         27.8284,  13.9284, 127.2121, 142.8907,  15.3647,  16.8009,  17.6990],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.8, acc=0.85, AUC=0.902, val_acc=0.833, val_AUC=0.886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([124.3884,  15.9982, 130.2033, 133.1180,  71.4509, 127.8524,  15.0075,\n",
      "         27.3939,  13.9466, 128.4925, 139.2204,  15.2176,  17.0903,  17.4449],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.44it/s, loss=31.9, acc=0.85, AUC=0.901, val_acc=0.844, val_AUC=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([124.7350,  16.0385, 125.7477, 147.0988,  68.7401, 119.7456,  15.2394,\n",
      "         26.7323,  13.9960, 125.1742, 143.8907,  15.1057,  17.3958,  17.1853],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.41it/s, loss=31.5, acc=0.851, AUC=0.904, val_acc=0.838, val_AUC=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([127.0208,  16.0673, 127.1300, 140.5436,  71.1194, 120.5889,  15.4151,\n",
      "         26.3323,  14.0293, 126.8766, 142.1536,  14.9846,  17.6394,  16.9242],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.3, acc=0.853, AUC=0.905, val_acc=0.834, val_AUC=0.892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.5286,  16.1276, 128.6547, 135.6612,  72.4351, 119.4459,  15.5787,\n",
      "         25.9482,  14.0303, 129.5141, 141.4316,  14.8736,  17.9037,  16.6919],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.5, acc=0.85, AUC=0.904, val_acc=0.846, val_AUC=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([126.0489,  16.1871, 128.4966, 135.8232,  69.3510, 123.0402,  15.7669,\n",
      "         25.4805,  14.0255, 127.6665, 145.3963,  14.7944,  18.2486,  16.4993],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31.2, acc=0.853, AUC=0.906, val_acc=0.843, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.8001,  16.2644, 128.3300, 139.5569,  68.3394, 118.2419,  15.9332,\n",
      "         25.1433,  14.0040, 129.7420, 141.9045,  14.6894,  18.5659,  16.3099],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31.2, acc=0.853, AUC=0.906, val_acc=0.846, val_AUC=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.9082,  16.3380, 128.1392, 137.1594,  67.8300, 119.7956,  16.1142,\n",
      "         24.8593,  13.9804, 131.0216, 141.1136,  14.5572,  18.8694,  16.1391],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.4, acc=0.852, AUC=0.905, val_acc=0.846, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.3995,  16.4253, 127.8724, 139.7092,  66.9354, 121.1999,  16.2434,\n",
      "         24.4618,  13.9775, 129.2397, 142.6965,  14.4684,  19.2425,  15.9535],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.1, acc=0.853, AUC=0.907, val_acc=0.843, val_AUC=0.894]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.7322,  16.4476, 127.4863, 135.5725,  66.9260, 122.6906,  16.3737,\n",
      "         24.1980,  13.9206, 131.3122, 142.3084,  14.3966,  19.6985,  15.7618],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.2, acc=0.853, AUC=0.906, val_acc=0.842, val_AUC=0.897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.8545,  16.4357, 127.6277, 139.4634,  64.9636, 123.1467,  16.5517,\n",
      "         23.9566,  13.8989, 130.0318, 141.8566,  14.3299,  20.0884,  15.6195],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31.2, acc=0.853, AUC=0.906, val_acc=0.846, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.7557,  16.4518, 127.4215, 139.0081,  64.0316, 121.0303,  16.7420,\n",
      "         23.7274,  13.8475, 129.4022, 145.2256,  14.2570,  20.4284,  15.4959],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=31.1, acc=0.853, AUC=0.907, val_acc=0.845, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([131.1312,  16.4811, 128.0812, 137.9942,  64.0999, 118.0376,  16.8782,\n",
      "         23.5829,  13.8147, 129.9757, 146.4327,  14.1472,  20.8381,  15.3304],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.8, acc=0.854, AUC=0.908, val_acc=0.848, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.6270,  16.5033, 126.6399, 134.8629,  65.6034, 118.3378,  17.0173,\n",
      "         23.4871,  13.7496, 130.5005, 149.0601,  14.0349,  21.2306,  15.1704],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.9, acc=0.853, AUC=0.908, val_acc=0.846, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.9037,  16.5718, 126.3939, 135.1582,  66.3155, 121.3328,  17.1598,\n",
      "         23.4009,  13.6566, 132.8241, 142.4708,  13.9156,  21.7158,  15.0057],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=30.9, acc=0.854, AUC=0.908, val_acc=0.844, val_AUC=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.7477,  16.6087, 126.7756, 134.5523,  64.6308, 122.2639,  17.3298,\n",
      "         23.2283,  13.5992, 133.1584, 143.0127,  13.8470,  22.2086,  14.8621],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.9, acc=0.854, AUC=0.908, val_acc=0.846, val_AUC=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.6065,  16.6220, 126.4933, 134.6382,  63.7733, 121.5932,  17.4922,\n",
      "         23.1692,  13.5544, 131.3961, 146.3798,  13.7672,  22.6175,  14.7221],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=31, acc=0.854, AUC=0.907, val_acc=0.847, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.1174,  16.6076, 124.8298, 144.0392,  62.6972, 121.5180,  17.6912,\n",
      "         23.0847,  13.5284, 129.6209, 142.8073,  13.6974,  22.9915,  14.5943],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.27it/s, loss=30.6, acc=0.856, AUC=0.909, val_acc=0.845, val_AUC=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([131.7673,  16.5650, 125.3368, 134.3773,  64.1625, 120.9578,  17.8489,\n",
      "         22.9844,  13.4710, 131.5754, 146.2420,  13.6251,  23.4467,  14.4649],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=30.7, acc=0.855, AUC=0.909, val_acc=0.838, val_AUC=0.898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.6136,  16.5544, 125.6721, 133.2791,  65.2541, 124.9176,  18.0590,\n",
      "         22.8621,  13.3907, 132.7824, 141.5821,  13.5113,  24.0038,  14.3427],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.7, acc=0.855, AUC=0.909, val_acc=0.847, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([131.8770,  16.5570, 124.4995, 135.8412,  64.7215, 123.7702,  18.3688,\n",
      "         22.6967,  13.3211, 135.6355, 137.3806,  13.4007,  24.5327,  14.2224],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.6, acc=0.855, AUC=0.909, val_acc=0.846, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([133.4767,  16.5739, 126.1285, 133.1617,  65.5016, 122.2295,  18.6238,\n",
      "         22.5251,  13.2131, 135.1095, 137.6570,  13.2840,  25.2477,  14.0927],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.41it/s, loss=30.7, acc=0.854, AUC=0.909, val_acc=0.838, val_AUC=0.895]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.5283,  16.5855, 125.1288, 131.6200,  64.8490, 125.2965,  18.8508,\n",
      "         22.4033,  13.1395, 132.4077, 142.9564,  13.1919,  25.8852,  13.9822],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=30.8, acc=0.855, AUC=0.908, val_acc=0.849, val_AUC=0.906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.5707,  16.5974, 120.6586, 137.0148,  63.0216, 125.3156,  19.0879,\n",
      "         22.2601,  13.0813, 131.8459, 144.8182,  13.1117,  26.5542,  13.8869],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.5, acc=0.856, AUC=0.91, val_acc=0.845, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([132.5647,  16.6110, 123.3477, 133.0033,  63.8547, 124.6871,  19.3349,\n",
      "         22.2536,  12.9350, 132.7397, 141.3015,  12.9877,  27.4447,  13.7594],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.6, acc=0.854, AUC=0.909, val_acc=0.847, val_AUC=0.908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([132.0530,  16.5959, 121.4454, 134.1866,  63.1071, 127.2297,  19.5749,\n",
      "         22.2182,  12.8465, 133.1195, 139.6160,  12.8866,  28.2874,  13.6582],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.42it/s, loss=30.5, acc=0.855, AUC=0.91, val_acc=0.844, val_AUC=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.4416,  16.6015, 121.0836, 135.7015,  63.7863, 126.3956,  19.8373,\n",
      "         22.1688,  12.7573, 133.0742, 140.4908,  12.7880,  29.2025,  13.4961],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.5, acc=0.855, AUC=0.91, val_acc=0.84, val_AUC=0.902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.7757,  16.6193, 120.7556, 138.8226,  63.5110, 125.3444,  20.1836,\n",
      "         22.1904,  12.6330, 134.9109, 136.8725,  12.6739,  30.1824,  13.3496],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.7, acc=0.855, AUC=0.909, val_acc=0.838, val_AUC=0.901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.8370,  16.6451, 118.3061, 135.0657,  61.9253, 126.9672,  20.5273,\n",
      "         22.0768,  12.5356, 134.6248, 142.1270,  12.5676,  31.3907,  13.2289],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.41it/s, loss=30.5, acc=0.856, AUC=0.91, val_acc=0.837, val_AUC=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([128.4901,  16.6742, 121.6351, 131.7854,  62.6056, 124.1348,  20.8413,\n",
      "         21.9341,  12.4470, 133.6166, 144.7003,  12.4713,  32.3671,  13.1220],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.43it/s, loss=30.7, acc=0.854, AUC=0.909, val_acc=0.843, val_AUC=0.905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([129.7317,  16.7055, 117.7386, 133.4590,  60.9776, 129.0655,  21.1516,\n",
      "         21.8458,  12.3668, 131.4819, 143.3666,  12.3793,  33.5186,  13.0365],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:03<00:00, 11.41it/s, loss=30.4, acc=0.855, AUC=0.911, val_acc=0.847, val_AUC=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([130.3251,  16.6935, 119.9304, 135.4450,  61.6927, 125.5841,  21.5125,\n",
      "         21.8529,  12.2738, 133.7882, 138.0812,  12.2931,  34.4315,  12.9213],\n",
      "       device='cuda:0', grad_fn=<DivBackward0>)\n",
      "test_acc: 0.8621586561203003\n",
      "test_auc: 0.9137257112789867\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "seed_set = [9,90,900,9000,90000]\n",
    "overall_train(x, y, seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7191489338874817"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.6960486173629761,\n",
    "     0.6990881562232971,\n",
    "     0.7203647494316101,\n",
    "     0.7355623245239258,\n",
    "     0.7446808218955994\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7843360551226942"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([0.765040650406504,\n",
    "     0.7699334319526627,\n",
    "     0.7728218852215284,\n",
    "     0.7938576945929887,\n",
    "     0.8200266134397871\n",
    "     ])/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
